{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25593a32-ed10-42ae-938f-98549f4ce10d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "#import wandb\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (Trainer, TrainingArguments, DataCollatorWithPadding,\n",
    "                          AutoTokenizer, AutoModelForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39bcd8e-5b78-42c4-bd92-edaf7e4259bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"microsoft/mpnet-base\"\n",
    "dataset_path = '../../bin/multirc_dataset.hf'\n",
    "output_dir = 'results/hp-tuning'\n",
    "model_max_length = 512\n",
    "eval_steps = 1000\n",
    "eval_accumulation_steps = 2\n",
    "save_total_limit = 4\n",
    "batch_size = 32\n",
    "num_epochs = 8\n",
    "learning_rate = 3e-05\n",
    "seed = 42\n",
    "metric = 'accuracy'\n",
    "entity = 'ai-aloe'\n",
    "project_name = 'short answer scoring'\n",
    "\n",
    "id2label = {0: \"incorrect_answer\", 1: \"correct_answer\"}\n",
    "label2id = {\"incorrect_answer\": 0, \"correct_answer\": 1}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    max_length=model_max_length,\n",
    "    )\n",
    "\n",
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,\n",
    "                                                               num_labels=2,\n",
    "                                                               id2label=id2label,\n",
    "                                                               label2id=label2id)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b577b9-82e6-4e79-b9e2-02ac160794e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858c9d3a387942d9a0597fe20b559d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b624fcbb34204d728669a918e5121b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e539bf57d8467ab050efe561df55db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3962 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def preprocess_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=True, truncation=True)\n",
    "    \n",
    "ds = DatasetDict.load_from_disk(dataset_path)\n",
    "ds = ds.map(preprocess_function, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adb69fa9-9d7a-4c7d-8728-236085421da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['index', 'text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 19170\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['index', 'text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4080\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['index', 'text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3962\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e7a94cb-085a-4a13-9c34-8a666c5139a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/project-archive/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Wed May 15 22:14:12 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe26ce5d-9aba-4b42-92da-44b272eb794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "376a9939-1fae-45f3-b9e4-81872473802e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/jovyan/conda_envs/wes-env/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 132/4800 01:36 < 57:51, 1.34 it/s, Epoch 0.22/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 40\u001b[0m\n\u001b[1;32m     29\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     30\u001b[0m     model_init \u001b[38;5;241m=\u001b[39m model_init,\n\u001b[1;32m     31\u001b[0m     args \u001b[38;5;241m=\u001b[39m training_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\u001b[39;00m\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/wes-env/lib/python3.12/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/wes-env/lib/python3.12/site-packages/transformers/trainer.py:2536\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2537\u001b[0m ):\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = f'./results/mpnet_checkpoints',\n",
    "    optim = 'adamw_torch',\n",
    "    num_train_epochs = num_epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    weight_decay = 0.01,\n",
    "    learning_rate = learning_rate,\n",
    "    logging_dir = f'./logs/content',\n",
    "    save_total_limit = 10,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'accuracy',\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\", \n",
    "    greater_is_better = True,\n",
    "    seed=seed,\n",
    "    log_level = 'error',  \n",
    "    disable_tqdm = False, \n",
    ") \n",
    "\n",
    "    # Call the Trainer\n",
    "trainer = Trainer(\n",
    "    model_init = model_init,\n",
    "    args = training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset = ds['train'],\n",
    "    eval_dataset = ds['valid'],\n",
    "    compute_metrics = compute_metrics\n",
    "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c5a1d-283f-411e-8bb4-1babeb5c15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "preds, labels, metrics= trainer.predict(ds['test'])\n",
    "predictions = np.argmax(preds, axis=1)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4a3df-2867-476a-8720-bdfd12a311ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(labels, predictions)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['incorrect', 'correct'])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.title('Predicted and True Classifications of Correct and Incorrect Answers (MPnet)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e25146-95ad-40e7-8e4e-8e72d1f4552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76c762e9-caf1-4a8a-88b6-a5a1d823338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../bin/mpnet_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f3c597-f9a6-47da-a0e5-5684dc165e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6758da99-6207-4d1a-9408-4dacc11fb4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378378378378378"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.cohen_kappa_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c886c2e-9aab-4900-8c16-e795f9f70bc9",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3637db10-feba-483f-bdbc-87e8fa19cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccc815362d4454899eb6afc14d614c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1846d527dd4642cebbfd4f3c96343f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ce153873414463825bfb18a409cb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3962 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  correct_answer       0.80      0.76      0.78      1722\n",
      "incorrect_answer       0.82      0.85      0.84      2240\n",
      "\n",
      "        accuracy                           0.81      3962\n",
      "       macro avg       0.81      0.81      0.81      3962\n",
      "    weighted avg       0.81      0.81      0.81      3962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from time import perf_counter\n",
    "from sklearn import metrics\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "dataset_path = '../../bin/multirc_dataset.hf'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "def preprocess_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=True, truncation=True)\n",
    "    \n",
    "ds = DatasetDict.load_from_disk(dataset_path)\n",
    "ds = ds.map(preprocess_function, batched=False)\n",
    "\n",
    "\n",
    "preds = []\n",
    "times = []\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"wesleymorris/short-answer-classification\").to(device)\n",
    "for text in ds['test']['text']:\n",
    "    start_time = perf_counter()\n",
    "    inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    preds.append(model.config.id2label[predicted_class_id])\n",
    "    times.append(perf_counter()-start_time)\n",
    "\n",
    "df = ds['test'].to_pandas()\n",
    "df['preds']=preds\n",
    "df['times']=times\n",
    "\n",
    "labels = []\n",
    "for x in ds['test']['labels']:\n",
    "    if x == 1:\n",
    "        labels.append('correct_answer' )\n",
    "    else: \n",
    "        labels.append('incorrect_answer') \n",
    "\n",
    "print(metrics.classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8439599-e718-4e88-8845-3f3ccba3de0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ca77810-592b-4bee-b9ea-c605732a2598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df.to_csv('mpnet-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d66046d8-e747-4e3d-b845-ff04afe39227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  correct_answer       0.80      0.76      0.78      1722\n",
      "incorrect_answer       0.82      0.85      0.84      2240\n",
      "\n",
      "        accuracy                           0.81      3962\n",
      "       macro avg       0.81      0.81      0.81      3962\n",
      "    weighted avg       0.81      0.81      0.81      3962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for x in ds['test']['labels']:\n",
    "    if x == 1:\n",
    "        labels.append('correct_answer' )\n",
    "    else: \n",
    "        labels.append('incorrect_answer') \n",
    "\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(metrics.classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44dd3524-430f-409a-95df-98a07f254504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dc2d2fdb05453c90b8d08f2f9e0c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcc9afc1-a5ee-4569-a9c3-a27e7ae380eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fc1b6f16b14f25aa268a784ebcb371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee593e6d64fb4c519181a65cf5692686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/wesleymorris/short-answer-classification/commit/7307cc1eba077afbdfc9be2e2559910e403996bc', commit_message='Upload tokenizer', commit_description='', oid='7307cc1eba077afbdfc9be2e2559910e403996bc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"short-answer-classification\")\n",
    "tokenizer.push_to_hub(\"short-answer-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46942ad-a5c3-4a55-a171-5f7b92720d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsection_num</th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>mpnet_response</th>\n",
       "      <th>bleurt_response</th>\n",
       "      <th>correct_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subsection_num, source, question, answer, mpnet_response, bleurt_response, correct_response]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "dataset = load_dataset(\"tiedaar/question_scoring_stresstest\")['train'].to_pandas()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a648ab-acaa-44f1-8ad0-35d50a4ce948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ABC', 'Hello World', '2023-05-10 04:53:08.014230'],\n",
       "        num_rows: 202\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e35e75-40c2-4884-bc2f-fc2807527579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wes-env]",
   "language": "python",
   "name": "conda-env-wes-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
