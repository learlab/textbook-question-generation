{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd08806-7183-483f-87d3-d3560880b0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/mpnet-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/mpnet-base\")\n",
    "\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4c3c0b-0df3-4c8f-b37d-4deddf3ae48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset length:  1569\n",
      "Dataset excluding subsections with length < 21 words: 1542\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/aqag-chatgpt-vicuna.csv', index_col=0)\n",
    "df['id'] = df.apply(lambda row: str(row['index']) + '-' + row['type'], axis=1)\n",
    "print('Original dataset length: ', len(df))\n",
    "\n",
    "# remove subsections with less than 20 words\n",
    "df.loc[:,'text_length'] = df['raw_text'].apply(lambda x: len(str(x).split()))\n",
    "df = df[df['text_length'] > 20]\n",
    "df['text_length'].plot.hist(bins=20)\n",
    "\n",
    "print('Dataset excluding subsections with length < 21 words:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "391270b7-0ceb-4dac-9bb3-cb2ac2f7f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['index', 'id', 'question', 'correct_answer', 'incorrect_answer', 'correct_answer_vicuna']]\n",
    "df1.columns = ['index', 'id', 'question', 'gold_answer', 'incorrect_answer', 'correct_answer']\n",
    "df2 = pd.melt(df1, \n",
    "             id_vars=['index','id', 'question', 'gold_answer'],\n",
    "             value_vars=['incorrect_answer', 'correct_answer'],\n",
    "             var_name='labels',\n",
    "             value_name='answer')\n",
    "df2['text'] = df2['answer'] + tokenizer.sep_token + df2['gold_answer']\n",
    "df2['labels'] = df2['labels'].apply(lambda x: 0 if x=='incorrect_answer' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "632f578e-ae0b-42c0-9936-09860f9bf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['index', 'id', 'question', 'correct_answer', 'incorrect_answer', 'correct_answer_vicuna']]\n",
    "df1.columns = ['index', 'id', 'question', 'gold_answer', 'incorrect_answer', 'correct_answer']\n",
    "df2 = pd.melt(df1, \n",
    "             id_vars=['index','id', 'question', 'gold_answer'],\n",
    "             value_vars=['incorrect_answer', 'correct_answer'],\n",
    "             var_name='labels',\n",
    "             value_name='answer')\n",
    "df2['text'] = df2['answer'] + tokenizer.sep_token + df2['gold_answer']\n",
    "df2['labels'] = df2['labels'].apply(lambda x: 0 if x=='incorrect_answer' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1704d9c-8f3b-44ef-8e15-cd8b04170560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "subsection_index = df['index'].drop_duplicates()\n",
    "train_index, validtest_index = train_test_split(subsection_index, test_size=0.3,train_size=0.7)\n",
    "valid_index, test_index = train_test_split(validtest_index, test_size=0.5, train_size=0.5)\n",
    "\n",
    "train_df = df2[df2['index'].isin(train_index)].dropna()\n",
    "valid_df = df2[df2['index'].isin(valid_index)].dropna()\n",
    "test_df = df2[df2['index'].isin(test_index)].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "347423cf-4dc7-4780-9491-7d6520093006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'labels'],\n",
       "        num_rows: 2031\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'text', 'labels'],\n",
       "        num_rows: 436\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'labels'],\n",
       "        num_rows: 444\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(train_df[['id', 'text', 'labels']], preserve_index=False)\n",
    "ds['valid'] = Dataset.from_pandas(valid_df[['id', 'text', 'labels']], preserve_index=False)\n",
    "ds['test'] = Dataset.from_pandas(test_df[['id', 'text', 'labels']], preserve_index=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8daa9a80-50f2-4723-8c15-b8405fb3ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def buildDataset(df):\n",
    "#     full_dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "#     # 70% train, 30% test\n",
    "#     train_valid = full_dataset.train_test_split(test_size=0.3, seed=seed)\n",
    "#     valid_test = train_valid['test'].train_test_split(test_size=0.5, seed=seed)\n",
    "    \n",
    "#     final_dataset = DatasetDict({\n",
    "#         'train': train_valid['train'],\n",
    "#         'valid': valid_test['train'],\n",
    "#         'test': valid_test['test']})\n",
    "#     print(final_dataset)\n",
    "#     return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5856e80-9acf-4353-a62c-82b2bbd1b936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2031 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/436 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.save_to_disk(\"../bin/aqag.hf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a169058f-3e63-4c43-8632-6c9dafcb77f7",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342cb72c-83b6-4b4c-9b67-dc734c896ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (Trainer, TrainingArguments, DataCollatorWithPadding,\n",
    "                          AutoTokenizer, AutoModelForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0038758b-6075-4b26-bd27-ba70add7f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"microsoft/mpnet-base\"\n",
    "dataset_path = '../bin/multirc_dataset.hf'\n",
    "output_dir = 'results/hp-tuning'\n",
    "model_max_length = 512\n",
    "eval_steps = 1000\n",
    "eval_accumulation_steps = 2\n",
    "save_total_limit = 4\n",
    "batch_size = 32\n",
    "sweep_id = None\n",
    "dry_run = False\n",
    "metric = 'accuracy'\n",
    "entity = 'ai-aloe'\n",
    "project_name = 'short answer scoring'\n",
    "\n",
    "id2label = {0: \"incorrect_answer\", 1: \"correct_answer\"}\n",
    "label2id = {\"incorrect_answer\": 0, \"correct_answer\": 1}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    max_length=model_max_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1826af57-9f6a-4841-959d-ac1f3392d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    return tokenizer(example[\"text\"])\n",
    "    \n",
    "def load_dataset(dataset_path):\n",
    "    ds = DatasetDict.load_from_disk(dataset_path)\n",
    "    ds = ds.map(preprocess_function, batched=False)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c3c64d-631b-4317-9d30-cd7aeb1bcd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf77cb8-8fb3-44ac-a8ed-8135b1c03534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    ''' The main training loop.\n",
    "    '''\n",
    "    wandb.init()\n",
    "    \n",
    "    config = wandb.config\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            num_labels=2,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id\n",
    "        )\n",
    "        \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy='steps',\n",
    "        save_strategy='steps',\n",
    "        logging_strategy='steps',\n",
    "        eval_steps=eval_steps,\n",
    "        save_steps=eval_steps,\n",
    "        eval_accumulation_steps=eval_accumulation_steps,\n",
    "        save_total_limit=save_total_limit,\n",
    "        optim='adamw_torch',\n",
    "        learning_rate=config.learning_rate,\n",
    "        num_train_epochs=config.epochs,\n",
    "        weight_decay=config.weight_decay,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        load_best_model_at_end=False,\n",
    "        disable_tqdm=False,\n",
    "        report_to='wandb',\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset_dict['train'],\n",
    "        eval_dataset=dataset_dict['valid'],\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d09533d2-b636-43bc-829d-652813edbb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/active-projects/textbook-question-generation/bin/aqag.hf/train/cache-5b977ada71e85085.arrow\n",
      "Loading cached processed dataset at /home/jovyan/active-projects/textbook-question-generation/bin/aqag.hf/valid/cache-1aac21e4ae60c552.arrow\n",
      "Loading cached processed dataset at /home/jovyan/active-projects/textbook-question-generation/bin/aqag.hf/test/cache-cbfad58d25290f44.arrow\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: i7zmhhch\n",
      "Sweep URL: https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: run ai-aloe/automatic question and answer scoring/epwnsa5f was previously created and deleted; try a new run name (<Response [409]>)\n",
      "Thread SenderThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/apis/normalize.py\", line 41, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 1690, in upsert_run\n",
      "    response = self.gql(\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 257, in gql\n",
      "    ret = self._retry_gql(\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/retry.py\", line 131, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 285, in execute\n",
      "    return self.client.execute(*args, **kwargs)  # type: ignore\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n",
      "    result = self._get_result(document, *args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n",
      "    return self.transport.execute(document, *args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/gql_request.py\", line 56, in execute\n",
      "    request.raise_for_status()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/requests/models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://api.wandb.ai/graphql\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 93, in _run\n",
      "    self._debounce()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 334, in _debounce\n",
      "    self._sm.debounce()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 551, in debounce\n",
      "    self._maybe_update_config(always=final)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 528, in _maybe_update_config\n",
      "    self._debounce_config()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 557, in _debounce_config\n",
      "    self._api.upsert_run(\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/apis/normalize.py\", line 51, in wrapper\n",
      "    raise CommError(message, error)\n",
      "wandb.errors.CommError: run ai-aloe/automatic question and answer scoring/epwnsa5f was previously created and deleted; try a new run name (Error 409: Conflict)\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a7pg6fh4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9f9dqdm2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.092598104280929e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.85345974726543e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n",
      "Exception in thread Thread-52 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2136, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2373, in _on_finish\n",
      "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 298, in wait\n",
      "    on_probe(probe_handle)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2338, in _on_probe_exit\n",
      "    result = handle.wait(timeout=0)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 281, in wait\n",
      "    raise MailboxError(\"transport failed\")\n",
      "wandb.sdk.lib.mailbox.MailboxError: transport failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 299, in _run_job\n",
      "    wandb.finish()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3705, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 394, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 335, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1884, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1899, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2147, in _atexit_cleanup\n",
      "    self._backend.cleanup()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/backend/backend.py\", line 255, in cleanup\n",
      "    self.interface.join()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 638, in join\n",
      "    super().join()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 741, in join\n",
      "    _ = self._communicate_shutdown()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 551, in _communicate_shutdown\n",
      "    _ = self._communicate(record)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 285, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 60, in _communicate_async\n",
      "    future = self._router.send_and_receive(rec, local=local)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/interface/router.py\", line 94, in send_and_receive\n",
      "    self._send_message(rec)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/interface/router_sock.py\", line 36, in _send_message\n",
      "    self._sock_client.send_record_communicate(record)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 216, in send_record_communicate\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3705, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 394, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 335, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1884, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1897, in _finish\n",
      "    hook.call()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 443, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ec545b309146a3b025609a75418af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670615101854008, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4495cdda707741909f91fa94048e5b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669174396277717, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread WriterThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
      "    self._process(record)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 380, in _process\n",
      "    self._wm.write(record)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/writer.py\", line 154, in write\n",
      "    write_handler(record)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/writer.py\", line 164, in write_request\n",
      "    return write_request_handler(record)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/writer.py\", line 182, in write_request_status_report\n",
      "    self._write(record)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/writer.py\", line 131, in _write\n",
      "    self.open()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/writer.py\", line 71, in open\n",
      "    self._ds.open_for_write(self._settings.sync_file)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/internal/datastore.py\", line 87, in open_for_write\n",
      "    self._fp = open(fname, open_flags)\n",
      "FileExistsError: [Errno 17] File exists: '/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192359-9f9dqdm2/run-9f9dqdm2.wandb'\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n",
      "Exception in thread Thread-56 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_223/3945396169.py\", line 4, in train\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 1169, in init\n",
      "    raise e\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 1150, in init\n",
      "    run = wi.init()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 740, in init\n",
      "    result = run_init_handle.wait(\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 281, in wait\n",
      "    raise MailboxError(\"transport failed\")\n",
      "wandb.sdk.lib.mailbox.MailboxError: transport failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3705, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 394, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 335, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1884, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1912, in _finish\n",
      "    manager._inform_finish(run_id=self._run_id)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_manager.py\", line 224, in _inform_finish\n",
      "    svc_iface._svc_inform_finish(run_id=run_id)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/service/service_sock.py\", line 54, in _svc_inform_finish\n",
      "    self._sock_client.send(inform_finish=inform_finish)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 211, in send\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /tmp/ipykernel_223/3945396169.py 4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 9f9dqdm2 errored: MailboxError('transport failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /tmp/ipykernel_223/3945396169.py 4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: While tearing down the service manager. The following error has occurred: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ir9k703t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.924368062741957e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192418-ir9k703t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ir9k703t' target=\"_blank\">devout-sweep-2</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ir9k703t' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ir9k703t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n",
      "You're using a MPNetTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>192</td></tr><tr><td>train/total_flos</td><td>402494136936960.0</td></tr><tr><td>train/train_loss</td><td>0.38235</td></tr><tr><td>train/train_runtime</td><td>43.7677</td></tr><tr><td>train/train_samples_per_second</td><td>139.623</td></tr><tr><td>train/train_steps_per_second</td><td>4.387</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-sweep-2</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ir9k703t' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ir9k703t</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_192418-ir9k703t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 81epzaip with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.3394816837986323e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192548-81epzaip</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/81epzaip' target=\"_blank\">hopeful-sweep-3</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/81epzaip' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/81epzaip</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='256' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [256/256 00:58, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6caa35d4259460385bf6b980dcf2ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>256</td></tr><tr><td>train/total_flos</td><td>537453663895680.0</td></tr><tr><td>train/train_loss</td><td>0.37366</td></tr><tr><td>train/train_runtime</td><td>58.2262</td></tr><tr><td>train/train_samples_per_second</td><td>139.937</td></tr><tr><td>train/train_steps_per_second</td><td>4.397</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-sweep-3</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/81epzaip' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/81epzaip</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_192548-81epzaip/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mccazo16 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.7222883453449535e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192704-mccazo16</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/mccazo16' target=\"_blank\">skilled-sweep-4</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/mccazo16' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/mccazo16</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9b9c32c4224282a591e99a0da8be25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>192</td></tr><tr><td>train/total_flos</td><td>402494136936960.0</td></tr><tr><td>train/train_loss</td><td>0.41544</td></tr><tr><td>train/train_runtime</td><td>44.0181</td></tr><tr><td>train/train_samples_per_second</td><td>138.829</td></tr><tr><td>train/train_steps_per_second</td><td>4.362</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-sweep-4</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/mccazo16' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/mccazo16</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_192704-mccazo16/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8wmpi7m7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.4039359535747886e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192805-8wmpi7m7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/8wmpi7m7' target=\"_blank\">classic-sweep-5</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/8wmpi7m7' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/8wmpi7m7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='256' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [256/256 00:58, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1207bf38a184d9d85a9e9b20e69c85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.279275…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>256</td></tr><tr><td>train/total_flos</td><td>537453663895680.0</td></tr><tr><td>train/train_loss</td><td>0.36417</td></tr><tr><td>train/train_runtime</td><td>59.0257</td></tr><tr><td>train/train_samples_per_second</td><td>138.041</td></tr><tr><td>train/train_steps_per_second</td><td>4.337</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-5</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/8wmpi7m7' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/8wmpi7m7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_192805-8wmpi7m7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qmudgta7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.9726158930262455e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192948-qmudgta7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/qmudgta7' target=\"_blank\">glowing-sweep-6</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/qmudgta7' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/qmudgta7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b289bd4e833247708d9c77bb626251e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.282707…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>128</td></tr><tr><td>train/total_flos</td><td>267896387679360.0</td></tr><tr><td>train/train_loss</td><td>0.47261</td></tr><tr><td>train/train_runtime</td><td>29.2169</td></tr><tr><td>train/train_samples_per_second</td><td>139.44</td></tr><tr><td>train/train_steps_per_second</td><td>4.381</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-sweep-6</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/qmudgta7' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/qmudgta7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_192948-qmudgta7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t5im43l2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.0958242772017908e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193036-t5im43l2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/t5im43l2' target=\"_blank\">misty-sweep-7</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/t5im43l2' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/t5im43l2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>192</td></tr><tr><td>train/total_flos</td><td>402494136936960.0</td></tr><tr><td>train/train_loss</td><td>0.45794</td></tr><tr><td>train/train_runtime</td><td>43.8271</td></tr><tr><td>train/train_samples_per_second</td><td>139.434</td></tr><tr><td>train/train_steps_per_second</td><td>4.381</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-sweep-7</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/t5im43l2' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/t5im43l2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_193036-t5im43l2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ejpd6eol with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.710155866948203e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193137-ejpd6eol</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ejpd6eol' target=\"_blank\">vivid-sweep-8</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ejpd6eol' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ejpd6eol</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:31, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f333e9dd7c234f5a877d72d4ece93b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.282759…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>128</td></tr><tr><td>train/total_flos</td><td>267896387679360.0</td></tr><tr><td>train/train_loss</td><td>0.47988</td></tr><tr><td>train/train_runtime</td><td>31.3317</td></tr><tr><td>train/train_samples_per_second</td><td>130.028</td></tr><tr><td>train/train_steps_per_second</td><td>4.085</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vivid-sweep-8</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ejpd6eol' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/ejpd6eol</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_193137-ejpd6eol/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1v2ep2k6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.3478840296179905e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a698f178361b469fb7e78e8430286628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667015431836868, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193249-1v2ep2k6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/1v2ep2k6' target=\"_blank\">resilient-sweep-9</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/1v2ep2k6' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/1v2ep2k6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>192</td></tr><tr><td>train/total_flos</td><td>402494136936960.0</td></tr><tr><td>train/train_loss</td><td>0.42133</td></tr><tr><td>train/train_runtime</td><td>43.7983</td></tr><tr><td>train/train_samples_per_second</td><td>139.526</td></tr><tr><td>train/train_steps_per_second</td><td>4.384</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resilient-sweep-9</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/1v2ep2k6' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/1v2ep2k6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_193249-1v2ep2k6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3zhqsqor with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.901231089481695e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193404-3zhqsqor</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/3zhqsqor' target=\"_blank\">expert-sweep-10</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/3zhqsqor' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/3zhqsqor</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 01:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c821ae45d62408bbe469f5008528145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.279265…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>192</td></tr><tr><td>train/total_flos</td><td>402494136936960.0</td></tr><tr><td>train/train_loss</td><td>0.38293</td></tr><tr><td>train/train_runtime</td><td>65.3321</td></tr><tr><td>train/train_samples_per_second</td><td>93.537</td></tr><tr><td>train/train_steps_per_second</td><td>2.939</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-10</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/3zhqsqor' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/3zhqsqor</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_193404-3zhqsqor/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2po1qo5f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.1564144587423063e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193525-2po1qo5f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2po1qo5f' target=\"_blank\">curious-sweep-11</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2po1qo5f' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2po1qo5f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 01:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44ec11b52a74cfea332957158669c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.279296…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>320</td></tr><tr><td>train/total_flos</td><td>671969190948480.0</td></tr><tr><td>train/train_loss</td><td>0.34668</td></tr><tr><td>train/train_runtime</td><td>98.9913</td></tr><tr><td>train/train_samples_per_second</td><td>102.888</td></tr><tr><td>train/train_steps_per_second</td><td>3.233</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-sweep-11</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2po1qo5f' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2po1qo5f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_193525-2po1qo5f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uj2lfw4j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.9444370604052582e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193723-uj2lfw4j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/uj2lfw4j' target=\"_blank\">silver-sweep-12</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/uj2lfw4j' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/uj2lfw4j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>128</td></tr><tr><td>train/total_flos</td><td>267896387679360.0</td></tr><tr><td>train/train_loss</td><td>0.47676</td></tr><tr><td>train/train_runtime</td><td>51.4564</td></tr><tr><td>train/train_samples_per_second</td><td>79.174</td></tr><tr><td>train/train_steps_per_second</td><td>2.488</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sweep-12</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/uj2lfw4j' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/uj2lfw4j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_193723-uj2lfw4j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 36ngwzdb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.0275363350065345e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193834-36ngwzdb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/36ngwzdb' target=\"_blank\">morning-sweep-13</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/36ngwzdb' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/36ngwzdb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='256' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [256/256 01:42, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9b38a8d43b4cecba49ec517ab266a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>256</td></tr><tr><td>train/total_flos</td><td>537453663895680.0</td></tr><tr><td>train/train_loss</td><td>0.40944</td></tr><tr><td>train/train_runtime</td><td>102.5481</td></tr><tr><td>train/train_samples_per_second</td><td>79.455</td></tr><tr><td>train/train_steps_per_second</td><td>2.496</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-sweep-13</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/36ngwzdb' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/36ngwzdb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_193834-36ngwzdb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xi5ably8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.9867049311627343e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194036-xi5ably8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/xi5ably8' target=\"_blank\">ruby-sweep-14</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/xi5ably8' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/xi5ably8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 02:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>320</td></tr><tr><td>train/total_flos</td><td>671969190948480.0</td></tr><tr><td>train/train_loss</td><td>0.28198</td></tr><tr><td>train/train_runtime</td><td>125.4138</td></tr><tr><td>train/train_samples_per_second</td><td>81.211</td></tr><tr><td>train/train_steps_per_second</td><td>2.552</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-sweep-14</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/xi5ably8' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/xi5ably8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_194036-xi5ably8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2xhx5dfv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.6178178686140594e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194258-2xhx5dfv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2xhx5dfv' target=\"_blank\">fallen-sweep-15</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2xhx5dfv' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2xhx5dfv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c2e8ebf4984dbaae9d952eb9b5b2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.280745…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>128</td></tr><tr><td>train/total_flos</td><td>267896387679360.0</td></tr><tr><td>train/train_loss</td><td>0.49914</td></tr><tr><td>train/train_runtime</td><td>44.7293</td></tr><tr><td>train/train_samples_per_second</td><td>91.081</td></tr><tr><td>train/train_steps_per_second</td><td>2.862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fallen-sweep-15</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2xhx5dfv' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/2xhx5dfv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_194258-2xhx5dfv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o9uczkgc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.189896516709904e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194401-o9uczkgc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/o9uczkgc' target=\"_blank\">glowing-sweep-16</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/o9uczkgc' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/o9uczkgc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3ff0ac267d4d1f8016332d3cf25285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>192</td></tr><tr><td>train/total_flos</td><td>402494136936960.0</td></tr><tr><td>train/train_loss</td><td>0.44604</td></tr><tr><td>train/train_runtime</td><td>44.8397</td></tr><tr><td>train/train_samples_per_second</td><td>136.286</td></tr><tr><td>train/train_steps_per_second</td><td>4.282</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-sweep-16</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/o9uczkgc' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/o9uczkgc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_194401-o9uczkgc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zd9zw3yp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.3548128788871774e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194502-zd9zw3yp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/zd9zw3yp' target=\"_blank\">stellar-sweep-17</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/zd9zw3yp' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/zd9zw3yp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='256' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [256/256 00:59, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc10022e2068404ba744829c06a67d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>256</td></tr><tr><td>train/total_flos</td><td>537453663895680.0</td></tr><tr><td>train/train_loss</td><td>0.3674</td></tr><tr><td>train/train_runtime</td><td>60.3718</td></tr><tr><td>train/train_samples_per_second</td><td>134.964</td></tr><tr><td>train/train_steps_per_second</td><td>4.24</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-17</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/zd9zw3yp' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/zd9zw3yp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_194502-zd9zw3yp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 49mripvn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.040782907037013e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194618-49mripvn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/49mripvn' target=\"_blank\">atomic-sweep-18</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/49mripvn' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/49mripvn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>192</td></tr><tr><td>train/total_flos</td><td>402494136936960.0</td></tr><tr><td>train/train_loss</td><td>0.48835</td></tr><tr><td>train/train_runtime</td><td>51.5851</td></tr><tr><td>train/train_samples_per_second</td><td>118.464</td></tr><tr><td>train/train_steps_per_second</td><td>3.722</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">atomic-sweep-18</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/49mripvn' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/49mripvn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_194618-49mripvn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: urnwpode with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.6422027904832395e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194724-urnwpode</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/urnwpode' target=\"_blank\">spring-sweep-19</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/urnwpode' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/urnwpode</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='256' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [256/256 00:58, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55b5593cf004628bb280b0fbe6cb355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.279488…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>256</td></tr><tr><td>train/total_flos</td><td>537453663895680.0</td></tr><tr><td>train/train_loss</td><td>0.34411</td></tr><tr><td>train/train_runtime</td><td>58.9899</td></tr><tr><td>train/train_samples_per_second</td><td>138.125</td></tr><tr><td>train/train_steps_per_second</td><td>4.34</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-sweep-19</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/urnwpode' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/urnwpode</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_194724-urnwpode/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pxuuit3o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.6108607293181748e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194841-pxuuit3o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/pxuuit3o' target=\"_blank\">royal-sweep-20</a></strong> to <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/sweeps/i7zmhhch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/pxuuit3o' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/pxuuit3o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 01:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69ee281720544988b3611e6c62f4370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.279361…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>320</td></tr><tr><td>train/total_flos</td><td>671969190948480.0</td></tr><tr><td>train/train_loss</td><td>0.32072</td></tr><tr><td>train/train_runtime</td><td>76.9638</td></tr><tr><td>train/train_samples_per_second</td><td>132.335</td></tr><tr><td>train/train_steps_per_second</td><td>4.158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-sweep-20</strong> at: <a href='https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/pxuuit3o' target=\"_blank\">https://wandb.ai/ai-aloe/short%20answer%20scoring/runs/pxuuit3o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_194841-pxuuit3o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict = load_dataset(dataset_path)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16, return_tensors='pt')\n",
    "\n",
    "if not sweep_id:\n",
    "    sweep_goal = 'maximize'\n",
    "        \n",
    "    if dry_run:\n",
    "        sweep_name = 'dry-run'\n",
    "    else:\n",
    "        sweep_name = f'{model_name_or_path}'\n",
    "            \n",
    "    sweep_config = {\n",
    "        'name': sweep_name,\n",
    "        'method': 'bayes',\n",
    "        'metric': {\n",
    "            'name': f'eval/{metric}',\n",
    "            'goal': sweep_goal,\n",
    "        },\n",
    "        'parameters':\n",
    "        {\n",
    "            'epochs': {\n",
    "                'values': [2, 3, 4, 5]\n",
    "            },\n",
    "            'learning_rate': {\n",
    "                'distribution': 'uniform',\n",
    "                'min': 1e-5,\n",
    "                'max': 2e-5,\n",
    "            },\n",
    "            'weight_decay': {\n",
    "                'values': [0.3]\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep_config,\n",
    "                            entity=entity,\n",
    "                            project=project_name)\n",
    "\n",
    "else:\n",
    "    sweep_id = sweep_id\n",
    "        \n",
    "wandb.agent(sweep_id, train, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932a241-d265-4291-abed-320f67a8097c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wes_env]",
   "language": "python",
   "name": "conda-env-wes_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
