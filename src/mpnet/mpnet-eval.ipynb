{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53db5e02-2010-450a-9bc3-4c67bd02ba63",
   "metadata": {},
   "source": [
    "# MPNet Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2d8f6-f6fc-432b-9bf6-449447228b53",
   "metadata": {},
   "source": [
    "## Using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3edf980-9bf8-47e1-9cb0-36fe1709a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "100%|██████████| 3962/3962 [00:00<00:00, 1198459.00it/s]\n",
      "  0%|          | 2/3962 [00:00<09:05,  7.26it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 3962/3962 [00:35<00:00, 111.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  correct_answer       0.80      0.76      0.78      1722\n",
      "incorrect_answer       0.82      0.85      0.84      2240\n",
      "\n",
      "        accuracy                           0.81      3962\n",
      "       macro avg       0.81      0.81      0.81      3962\n",
      "    weighted avg       0.81      0.81      0.81      3962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "dataset_path = '../../bin/multirc_dataset.hf'\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pipe = pipeline('text-classification', model='tiedaar/short-answer-classification', device=0)\n",
    "ds = DatasetDict.load_from_disk(dataset_path)\n",
    "\n",
    "test_df = ds['test'].to_pandas()\n",
    "test_df['labels'] = test_df['labels'].progress_apply(lambda x: 'correct_answer' if x==1 else 'incorrect_answer')\n",
    "test_df['preds'] = test_df['text'].progress_apply(lambda x: pipe(x)[0]['label'])\n",
    "print(metrics.classification_report(test_df['labels'], test_df['preds']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b5008b-79ab-4a06-b156-085c13c6a28d",
   "metadata": {},
   "source": [
    "## Without pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02236d94-84ed-4d61-86db-3efedb5573b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3880ed2a31fd4ab7b0f866873a61777d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac24f6f961e49ed8485f89129ae1620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0133343b495b450f89674f78b50ab252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3962 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  correct_answer       0.80      0.76      0.78      1722\n",
      "incorrect_answer       0.82      0.85      0.84      2240\n",
      "\n",
      "        accuracy                           0.81      3962\n",
      "       macro avg       0.81      0.81      0.81      3962\n",
      "    weighted avg       0.81      0.81      0.81      3962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from time import perf_counter\n",
    "from sklearn import metrics\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "dataset_path = '../../bin/multirc_dataset.hf'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"wesleymorris/short-answer-classification\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"wesleymorris/short-answer-classification\")\n",
    "\n",
    "def preprocess_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=True, truncation=True)\n",
    "    \n",
    "ds = DatasetDict.load_from_disk(dataset_path)\n",
    "ds = ds.map(preprocess_function, batched=False)\n",
    "\n",
    "\n",
    "preds = []\n",
    "times = []\n",
    "\n",
    "for text in ds['test']['text']:\n",
    "    start_time = perf_counter()\n",
    "    inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    preds.append(model.config.id2label[predicted_class_id])\n",
    "    times.append(perf_counter()-start_time)\n",
    "\n",
    "df = ds['test'].to_pandas()\n",
    "df['preds']=preds\n",
    "df['times']=times\n",
    "\n",
    "labels = []\n",
    "for x in ds['test']['labels']:\n",
    "    if x == 1:\n",
    "        labels.append('correct_answer' )\n",
    "    else: \n",
    "        labels.append('incorrect_answer') \n",
    "\n",
    "print(metrics.classification_report(labels, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wes-env2]",
   "language": "python",
   "name": "conda-env-wes-env2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
