{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d41815-c811-42c2-ba42-a8bbcdbdf5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d32d2-c8d6-43b0-b569-1cd85d5bfb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from nltk import ngrams as nltk_ngrams\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report\n",
    "\n",
    "import evaluate\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# precision_metric = evaluate.load('precision')\n",
    "# recall_metric = evaluate.load('recall')\n",
    "# rouge_model = evaluate.load('rouge')\n",
    "# bleu_model = evaluate.load(\"bleu\")\n",
    "bleurt_model = evaluate.load(\"bleurt\", module_type=\"metric\", checkpoint=\"bleurt-20\")\n",
    "# similarity_model = SentenceTransformer('stsb-roberta-large')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b269d-7313-4a9f-badd-9efaaeb6c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/active-projects/textbook-question-generation/data/aqag-chatgpt-vicuna.csv')\n",
    "# df.rename({'correct_answer_vicuna': 'gold_answer'}, axis=1, inplace=True)\n",
    "df.rename({'correct_answer': 'gold_answer'}, axis=1, inplace=True)\n",
    "df.rename({'correct_answer_vicuna': 'correct_answer'}, axis=1, inplace=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588c523-931d-4716-87af-979d69c91af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape, df.dropna(subset=['clean_text', 'question', 'correct_answer', 'incorrect_answer', 'gold_answer']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5c883-3caa-4aa9-a311-7f070b179383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['clean_text', 'question', 'correct_answer', 'incorrect_answer', 'gold_answer'], inplace=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845ea36-2187-44fc-9f78-f94011781315",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_correct_df = df[['clean_text', 'question', 'gold_answer', 'correct_answer']]\n",
    "temp_correct_df.rename({'correct_answer': 'student_response'}, axis=1, inplace=True)\n",
    "temp_correct_df['true_label'] = 1\n",
    "# temp_correct_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3a941-6899-497e-9252-a4b504f0b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_incorrect_df = df[['clean_text', 'question', 'gold_answer', 'incorrect_answer']]\n",
    "temp_incorrect_df.rename({'incorrect_answer': 'student_response'}, axis=1, inplace=True)\n",
    "temp_incorrect_df['true_label'] = 0\n",
    "# temp_incorrect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d7efc-159d-47fc-9ea9-df8e3a918703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, temp_correct_df.shape, temp_incorrect_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a992a4f-570e-47a1-8e6a-efe90354d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([temp_correct_df, temp_incorrect_df]).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c0d35-f737-4fee-95dd-743bae8c48cf",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3465726-3645-44ef-8721-c7aa6cd6c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing steps for similarity computation:\n",
    "# 1. lower case\n",
    "# 2. remove non-alphanumeric characters except those bringing in context - (['@', '#', '$', '%', '*', '<', '>', '.', ','])\n",
    "# 3. remove stopwords\n",
    "# 4. lemmatize --- experiment\n",
    "\n",
    "def func_preprocessing(text:str, lemmatize:bool=False):\n",
    "\n",
    "    return_list = list()\n",
    "    doc = nlp(text.lower().strip())\n",
    "    for token in [token for token in doc]:\n",
    "        if (token.text.isalnum() or any(i in token.text and token.text.count(i) == 1 for i in ['@', '#', '$', '%', '<', '>', '.', ',', '+', '-', '*'])) and (not token.is_stop):\n",
    "            if lemmatize:\n",
    "                return_list.append(token.lemma_)\n",
    "            else:\n",
    "                return_list.append(token.text)\n",
    "    \n",
    "    return ' '.join(return_list)\n",
    "\n",
    "df['processed_gold_answer'] = df['gold_answer'].apply(lambda x: func_preprocessing(x))\n",
    "df['processed_student_response'] = df['student_response'].apply(lambda x: func_preprocessing(x))\n",
    "\n",
    "df['processed_lemmatized_gold_answer'] = df['gold_answer'].apply(lambda x: func_preprocessing(x, lemmatize=True))\n",
    "df['processed_lemmatized_student_response'] = df['student_response'].apply(lambda x: func_preprocessing(x, lemmatize=True))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c9906-ef91-4983-9d01-0d8b6955fbf1",
   "metadata": {},
   "source": [
    "#### Computing BLUERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d74f8b-d1fb-4c10-bc6c-9badc568a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = bleurt_model.compute(predictions=df['student_response'].tolist(), references=df['gold_answer'].tolist())['scores']\n",
    "df['processed_score'] = bleurt_model.compute(predictions=df['processed_student_response'].tolist(), references=df['processed_gold_answer'].tolist())['scores']\n",
    "df['processed_lemmatized_score'] = bleurt_model.compute(predictions=df['processed_lemmatized_student_response'].tolist(), references=df['processed_lemmatized_gold_answer'].tolist())['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc76dc-13d6-4693-9067-627ee914aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74616e2b-e063-41f1-abea-6c808c75c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('~/active-projects/textbook-question-generation/data/aqag-chatgpt-vicuna-bleurt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925edfe5-f96a-4e57-be94-780101e3c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('~/active-projects/textbook-question-generation/data/aqag-chatgpt-vicuna-bleurt.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe7764-3d12-4baa-a5e8-93680b1e56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f1511-7c86-4114-b914-40d9b05fa35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_score'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0d144-b475-45b0-9a87-a215b645b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_lemmatized_score'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ed356-a6bc-49d8-8927-8617f4d88b83",
   "metadata": {},
   "source": [
    "#### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1339924-70f0-4592-89c0-6adb3ba0a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['score'].apply(lambda x: 1 if x>0.8 else 0)\n",
    "df['processed_label'] = df['processed_score'].apply(lambda x: 1 if x>0.8 else 0)\n",
    "df['processed_lemmatized_label'] = df['processed_lemmatized_score'].apply(lambda x: 1 if x>0.8 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5120b7-5227-46e7-a290-af66ce046f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['true_label'], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244c21a-800a-434a-8c28-a7e7d20bca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df['true_label'], df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0b3a0-5fd7-4ccd-86e2-5e3d8316b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(df['true_label'], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563387a-c42d-4ba0-bb3d-7c6e9024a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['true_label'], df['processed_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281a39e-c006-43c4-be8f-87b73066ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df['true_label'], df['processed_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5765dd8-5ffb-4315-94b0-bded2f9a06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(df['true_label'], df['processed_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e455becd-0676-435f-b840-d54c9c54821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['true_label'], df['processed_lemmatized_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb87b8-a315-4252-9845-270757bce3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df['true_label'], df['processed_lemmatized_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb323721-a87b-497e-b525-9f305ef1fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(df['true_label'], df['processed_lemmatized_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8acd103-d102-43f2-8ac1-d692329f9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['true_label'] == 1]['score'].plot(kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a77f0-1665-494e-9616-15339246c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['true_label'] == 0]['score'].plot(kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f8fa5-9c66-43e3-98a4-52ff58ad4365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_vaibhav_autograder]",
   "language": "python",
   "name": "conda-env-env_vaibhav_autograder-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
