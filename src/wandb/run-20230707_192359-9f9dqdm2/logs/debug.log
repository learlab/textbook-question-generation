2023-07-07 19:23:59,700 INFO    Thread-58 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:23:59,700 INFO    Thread-58 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:23:59,701 INFO    Thread-58 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:23:59,701 INFO    Thread-58 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:23:59,701 INFO    Thread-58 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '9f9dqdm2', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-9f9dqdm2.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:23:59,701 INFO    Thread-58 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:23:59,701 INFO    Thread-58 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:23:59,701 INFO    Thread-58 (_run_job):223 [wandb_setup.py:_flush():76] cleaning up jupyter logic
2023-07-07 19:23:59,701 INFO    Thread-58 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192359-9f9dqdm2/logs/debug.log
2023-07-07 19:23:59,702 INFO    Thread-58 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192359-9f9dqdm2/logs/debug-internal.log
2023-07-07 19:23:59,702 INFO    Thread-58 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35f1a17190>
2023-07-07 19:23:59,703 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:23:59,703 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.092598104280929e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:23:59,703 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:23:59,703 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:23:59,722 INFO    Thread-58 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:23:59,727 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:23:59,727 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:23:59,730 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:23:59,730 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '9f9dqdm2', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-9f9dqdm2.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '9f9dqdm2', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-9f9dqdm2.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:23:59,731 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:23:59,732 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] cleaning up jupyter logic
2023-07-07 19:23:59,732 INFO    Thread-56 (_run_job):223 [wandb_setup.py:_flush():76] cleaning up jupyter logic
2023-07-07 19:23:59,732 INFO    Thread-56 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192359-9f9dqdm2/logs/debug.log
2023-07-07 19:23:59,732 INFO    Thread-56 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192359-9f9dqdm2/logs/debug.log
2023-07-07 19:23:59,733 INFO    Thread-56 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192359-9f9dqdm2/logs/debug-internal.log
2023-07-07 19:23:59,733 INFO    Thread-56 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192359-9f9dqdm2/logs/debug-internal.log
2023-07-07 19:23:59,733 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:23:59,733 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:23:59,733 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.092598104280929e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:23:59,733 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.092598104280929e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:23:59,733 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:23:59,733 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:23:59,734 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:23:59,734 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:23:59,747 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:23:59,747 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:23:59,777 INFO    Thread-56 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:23:59,777 INFO    Thread-56 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:23:59,788 INFO    Thread-58 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.092598104280929e-05, 'weight_decay': 0.3}
2023-07-07 19:23:59,788 INFO    Thread-58 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.092598104280929e-05, 'weight_decay': 0.3}
2023-07-07 19:23:59,797 INFO    Thread-58 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:23:59,797 INFO    Thread-58 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:23:59,797 INFO    Thread-58 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:23:59,797 INFO    Thread-58 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:23:59,797 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:23:59,797 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:23:59,809 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:23:59,809 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:23:59,842 INFO    Thread-56 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.092598104280929e-05, 'weight_decay': 0.3}
2023-07-07 19:23:59,842 INFO    Thread-56 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.092598104280929e-05, 'weight_decay': 0.3}
2023-07-07 19:23:59,844 INFO    Thread-56 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:23:59,844 INFO    Thread-56 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:23:59,845 INFO    Thread-56 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:23:59,845 INFO    Thread-56 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:23:59,845 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:23:59,845 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:23:59,848 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:23:59,848 INFO    Thread-58 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:23:59,859 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:23:59,859 INFO    Thread-56 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:24:00,307 WARNING MsgRouterThr:223 [router.py:message_loop():77] message_loop has been closed
2023-07-07 19:24:00,307 WARNING MsgRouterThr:223 [router.py:message_loop():77] message_loop has been closed
2023-07-07 19:24:05,934 WARNING MsgRouterThr:223 [router.py:message_loop():77] message_loop has been closed
2023-07-07 19:24:05,934 WARNING MsgRouterThr:223 [router.py:message_loop():77] message_loop has been closed
2023-07-07 19:24:09,937 ERROR   Thread-56 (_run_job):223 [wandb_init.py:init():1168] transport failed
Traceback (most recent call last):
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1150, in init
    run = wi.init()
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 740, in init
    result = run_init_handle.wait(
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 281, in wait
    raise MailboxError("transport failed")
wandb.sdk.lib.mailbox.MailboxError: transport failed
2023-07-07 19:24:09,937 ERROR   Thread-56 (_run_job):223 [wandb_init.py:init():1168] transport failed
Traceback (most recent call last):
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1150, in init
    run = wi.init()
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 740, in init
    result = run_init_handle.wait(
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 281, in wait
    raise MailboxError("transport failed")
wandb.sdk.lib.mailbox.MailboxError: transport failed
2023-07-07 19:24:09,939 INFO    Thread-56 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/automatic question and answer scoring/epwnsa5f
2023-07-07 19:24:09,939 INFO    Thread-56 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/automatic question and answer scoring/epwnsa5f
2023-07-07 19:24:09,940 INFO    Thread-56 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:24:09,940 INFO    Thread-56 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:24:09,940 INFO    Thread-56 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:24:09,940 INFO    Thread-56 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:24:09,940 INFO    Thread-56 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:24:09,940 INFO    Thread-56 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:24:14,923 ERROR   Thread-58 (_run_job):223 [wandb_init.py:init():1168] transport failed
Traceback (most recent call last):
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1150, in init
    run = wi.init()
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 740, in init
    result = run_init_handle.wait(
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 281, in wait
    raise MailboxError("transport failed")
wandb.sdk.lib.mailbox.MailboxError: transport failed
2023-07-07 19:24:14,923 ERROR   Thread-58 (_run_job):223 [wandb_init.py:init():1168] transport failed
Traceback (most recent call last):
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1150, in init
    run = wi.init()
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 740, in init
    result = run_init_handle.wait(
  File "/home/jovyan/conda_envs/WesleyEnv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 281, in wait
    raise MailboxError("transport failed")
wandb.sdk.lib.mailbox.MailboxError: transport failed
2023-07-07 19:24:14,925 ERROR   MainThread:223 [pyagent.py:_run_jobs_from_queue():226] Run 9f9dqdm2 errored: MailboxError('transport failed')
2023-07-07 19:24:14,925 ERROR   MainThread:223 [pyagent.py:_run_jobs_from_queue():226] Run 9f9dqdm2 errored: MailboxError('transport failed')
2023-07-07 19:24:18,427 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:24:18,427 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'ir9k703t', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-ir9k703t.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'ir9k703t', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-ir9k703t.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:24:18,428 INFO    Thread-63 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:24:18,429 INFO    Thread-63 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192418-ir9k703t/logs/debug.log
2023-07-07 19:24:18,429 INFO    Thread-63 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192418-ir9k703t/logs/debug.log
2023-07-07 19:24:18,429 INFO    Thread-63 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192418-ir9k703t/logs/debug-internal.log
2023-07-07 19:24:18,429 INFO    Thread-63 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192418-ir9k703t/logs/debug-internal.log
2023-07-07 19:24:18,429 INFO    Thread-63 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a8267e80>
2023-07-07 19:24:18,429 INFO    Thread-63 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a8267e80>
2023-07-07 19:24:18,430 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:24:18,430 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:24:18,430 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.924368062741957e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:24:18,430 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.924368062741957e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:24:18,431 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:24:18,431 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:24:18,431 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:24:18,431 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:24:18,444 INFO    Thread-63 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:24:18,444 INFO    Thread-63 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:24:18,454 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:24:18,454 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:24:18,474 INFO    Thread-63 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.924368062741957e-05, 'weight_decay': 0.3}
2023-07-07 19:24:18,474 INFO    Thread-63 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.924368062741957e-05, 'weight_decay': 0.3}
2023-07-07 19:24:18,476 INFO    Thread-63 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:24:18,476 INFO    Thread-63 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:24:18,476 INFO    Thread-63 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:24:18,476 INFO    Thread-63 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:24:18,476 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:24:18,476 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:24:18,486 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:24:18,486 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:24:18,776 INFO    Thread-63 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:24:18,776 INFO    Thread-63 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:24:18,933 INFO    Thread-63 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:24:18,933 INFO    Thread-63 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:24:18,933 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:24:18,933 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:24:25,324 INFO    Thread-63 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:24:25,324 INFO    Thread-63 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:24:25,325 INFO    Thread-63 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:24:25,325 INFO    Thread-63 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:24:25,325 INFO    Thread-63 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:24:25,325 INFO    Thread-63 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:24:25,325 INFO    Thread-63 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:24:25,325 INFO    Thread-63 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:24:25,327 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:24:25,327 INFO    Thread-63 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:24:27,227 INFO    Thread-63 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-24-27_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:24:27,227 INFO    Thread-63 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-24-27_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:25:10,994 INFO    Thread-63 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/ir9k703t
2023-07-07 19:25:10,994 INFO    Thread-63 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/ir9k703t
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:25:10,996 INFO    Thread-63 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:25:10,997 INFO    Thread-63 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:25:10,997 INFO    Thread-63 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:25:15,907 INFO    Thread-63 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:25:15,907 INFO    Thread-63 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:25:15,908 INFO    Thread-63 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:25:15,908 INFO    Thread-63 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:25:15,920 INFO    Thread-63 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:25:15,920 INFO    Thread-63 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:25:48,657 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:25:48,657 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '81epzaip', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-81epzaip.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '81epzaip', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-81epzaip.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:25:48,658 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:25:48,659 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:25:48,659 INFO    Thread-66 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:25:48,659 INFO    Thread-66 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192548-81epzaip/logs/debug.log
2023-07-07 19:25:48,659 INFO    Thread-66 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192548-81epzaip/logs/debug.log
2023-07-07 19:25:48,659 INFO    Thread-66 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192548-81epzaip/logs/debug-internal.log
2023-07-07 19:25:48,659 INFO    Thread-66 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192548-81epzaip/logs/debug-internal.log
2023-07-07 19:25:48,659 INFO    Thread-66 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35f100fee0>
2023-07-07 19:25:48,659 INFO    Thread-66 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35f100fee0>
2023-07-07 19:25:48,660 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:25:48,660 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:25:48,660 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.3394816837986323e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:25:48,660 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.3394816837986323e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:25:48,661 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:25:48,661 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:25:48,661 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:25:48,661 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:25:48,672 INFO    Thread-66 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:25:48,672 INFO    Thread-66 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:25:48,682 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:25:48,682 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:25:48,701 INFO    Thread-66 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.3394816837986323e-05, 'weight_decay': 0.3}
2023-07-07 19:25:48,701 INFO    Thread-66 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.3394816837986323e-05, 'weight_decay': 0.3}
2023-07-07 19:25:48,706 INFO    Thread-66 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:25:48,706 INFO    Thread-66 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:25:48,706 INFO    Thread-66 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:25:48,706 INFO    Thread-66 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:25:48,706 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:25:48,706 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:25:48,717 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:25:48,717 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:25:49,021 INFO    Thread-66 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:25:49,021 INFO    Thread-66 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:25:49,205 INFO    Thread-66 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:25:49,205 INFO    Thread-66 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:25:49,206 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:25:49,206 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:25:54,805 INFO    Thread-66 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:25:54,805 INFO    Thread-66 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:25:54,805 INFO    Thread-66 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:25:54,805 INFO    Thread-66 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:25:54,806 INFO    Thread-66 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:25:54,806 INFO    Thread-66 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:25:54,806 INFO    Thread-66 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:25:54,806 INFO    Thread-66 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:25:54,808 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:25:54,808 INFO    Thread-66 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:25:56,633 INFO    Thread-66 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-25-56_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:25:56,633 INFO    Thread-66 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-25-56_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:26:54,858 INFO    Thread-66 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/81epzaip
2023-07-07 19:26:54,858 INFO    Thread-66 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/81epzaip
2023-07-07 19:26:54,859 INFO    Thread-66 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:26:54,859 INFO    Thread-66 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:26:54,859 INFO    Thread-66 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:26:54,859 INFO    Thread-66 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:26:54,860 INFO    Thread-66 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:26:54,860 INFO    Thread-66 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:26:54,860 INFO    Thread-66 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:26:54,860 INFO    Thread-66 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:26:54,860 INFO    Thread-66 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:26:54,860 INFO    Thread-66 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:26:54,860 INFO    Thread-66 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:26:54,860 INFO    Thread-66 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:26:59,320 INFO    Thread-66 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:26:59,320 INFO    Thread-66 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:26:59,321 INFO    Thread-66 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:26:59,321 INFO    Thread-66 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:26:59,333 INFO    Thread-66 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:26:59,333 INFO    Thread-66 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:27:04,043 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:27:04,043 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:27:04,043 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:27:04,043 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'mccazo16', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-mccazo16.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'mccazo16', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-mccazo16.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192704-mccazo16/logs/debug.log
2023-07-07 19:27:04,044 INFO    Thread-69 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192704-mccazo16/logs/debug.log
2023-07-07 19:27:04,045 INFO    Thread-69 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192704-mccazo16/logs/debug-internal.log
2023-07-07 19:27:04,045 INFO    Thread-69 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192704-mccazo16/logs/debug-internal.log
2023-07-07 19:27:04,045 INFO    Thread-69 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3550741480>
2023-07-07 19:27:04,045 INFO    Thread-69 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3550741480>
2023-07-07 19:27:04,046 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:27:04,046 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:27:04,046 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.7222883453449535e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:27:04,046 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.7222883453449535e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:27:04,046 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:27:04,046 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:27:04,047 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:27:04,047 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:27:04,059 INFO    Thread-69 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:27:04,059 INFO    Thread-69 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:27:04,071 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:27:04,071 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:27:04,090 INFO    Thread-69 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.7222883453449535e-05, 'weight_decay': 0.3}
2023-07-07 19:27:04,090 INFO    Thread-69 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.7222883453449535e-05, 'weight_decay': 0.3}
2023-07-07 19:27:04,095 INFO    Thread-69 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:27:04,095 INFO    Thread-69 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:27:04,095 INFO    Thread-69 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:27:04,095 INFO    Thread-69 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:27:04,095 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:27:04,095 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:27:04,106 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:27:04,106 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:27:04,424 INFO    Thread-69 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:27:04,424 INFO    Thread-69 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:27:04,587 INFO    Thread-69 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:27:04,587 INFO    Thread-69 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:27:04,587 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:27:04,587 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:27:10,095 INFO    Thread-69 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:27:10,095 INFO    Thread-69 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:27:10,096 INFO    Thread-69 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:27:10,096 INFO    Thread-69 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:27:10,096 INFO    Thread-69 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:27:10,096 INFO    Thread-69 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:27:10,096 INFO    Thread-69 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:27:10,096 INFO    Thread-69 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:27:10,098 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:27:10,098 INFO    Thread-69 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:27:11,848 INFO    Thread-69 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-27-11_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:27:11,848 INFO    Thread-69 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-27-11_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:27:55,867 INFO    Thread-69 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/mccazo16
2023-07-07 19:27:55,867 INFO    Thread-69 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/mccazo16
2023-07-07 19:27:55,868 INFO    Thread-69 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:27:55,868 INFO    Thread-69 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:27:55,868 INFO    Thread-69 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:27:55,868 INFO    Thread-69 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:27:55,868 INFO    Thread-69 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:27:55,868 INFO    Thread-69 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:27:55,868 INFO    Thread-69 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:27:55,868 INFO    Thread-69 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:27:55,869 INFO    Thread-69 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:27:55,869 INFO    Thread-69 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:27:55,869 INFO    Thread-69 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:27:55,869 INFO    Thread-69 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:28:00,477 INFO    Thread-69 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:28:00,477 INFO    Thread-69 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:28:00,478 INFO    Thread-69 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:28:00,478 INFO    Thread-69 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:28:00,490 INFO    Thread-69 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:28:00,490 INFO    Thread-69 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:28:05,264 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:28:05,264 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:28:05,264 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:28:05,264 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:28:05,264 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:28:05,264 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:28:05,264 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:28:05,264 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:28:05,265 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '8wmpi7m7', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-8wmpi7m7.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:28:05,265 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '8wmpi7m7', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-8wmpi7m7.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:28:05,265 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:28:05,265 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:28:05,265 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:28:05,265 INFO    Thread-72 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:28:05,265 INFO    Thread-72 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192805-8wmpi7m7/logs/debug.log
2023-07-07 19:28:05,265 INFO    Thread-72 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192805-8wmpi7m7/logs/debug.log
2023-07-07 19:28:05,266 INFO    Thread-72 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192805-8wmpi7m7/logs/debug-internal.log
2023-07-07 19:28:05,266 INFO    Thread-72 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192805-8wmpi7m7/logs/debug-internal.log
2023-07-07 19:28:05,266 INFO    Thread-72 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3550619fc0>
2023-07-07 19:28:05,266 INFO    Thread-72 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3550619fc0>
2023-07-07 19:28:05,267 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:28:05,267 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:28:05,267 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.4039359535747886e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:28:05,267 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.4039359535747886e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:28:05,267 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:28:05,267 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:28:05,267 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:28:05,267 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:28:05,280 INFO    Thread-72 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:28:05,280 INFO    Thread-72 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:28:05,290 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:28:05,290 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:28:05,309 INFO    Thread-72 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.4039359535747886e-05, 'weight_decay': 0.3}
2023-07-07 19:28:05,309 INFO    Thread-72 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.4039359535747886e-05, 'weight_decay': 0.3}
2023-07-07 19:28:05,314 INFO    Thread-72 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:28:05,314 INFO    Thread-72 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:28:05,314 INFO    Thread-72 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:28:05,314 INFO    Thread-72 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:28:05,315 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:28:05,315 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:28:05,327 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:28:05,327 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:28:05,620 INFO    Thread-72 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:28:05,620 INFO    Thread-72 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:28:05,782 INFO    Thread-72 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:28:05,782 INFO    Thread-72 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:28:05,782 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:28:05,782 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:28:11,449 INFO    Thread-72 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:28:11,449 INFO    Thread-72 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:28:11,449 INFO    Thread-72 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:28:11,449 INFO    Thread-72 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:28:11,450 INFO    Thread-72 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:28:11,450 INFO    Thread-72 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:28:11,450 INFO    Thread-72 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:28:11,450 INFO    Thread-72 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:28:11,452 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:28:11,452 INFO    Thread-72 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:28:13,290 INFO    Thread-72 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-28-13_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:28:13,290 INFO    Thread-72 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-28-13_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:29:12,315 INFO    Thread-72 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/8wmpi7m7
2023-07-07 19:29:12,315 INFO    Thread-72 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/8wmpi7m7
2023-07-07 19:29:12,316 INFO    Thread-72 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:29:12,316 INFO    Thread-72 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:29:12,317 INFO    Thread-72 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:29:15,811 INFO    Thread-72 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:29:15,811 INFO    Thread-72 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:29:15,812 INFO    Thread-72 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:29:15,812 INFO    Thread-72 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:29:15,824 INFO    Thread-72 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:29:15,824 INFO    Thread-72 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:29:48,787 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:29:48,787 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:29:48,787 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:29:48,787 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'qmudgta7', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-qmudgta7.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'qmudgta7', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-qmudgta7.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:29:48,788 INFO    Thread-75 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:29:48,789 INFO    Thread-75 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192948-qmudgta7/logs/debug.log
2023-07-07 19:29:48,789 INFO    Thread-75 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192948-qmudgta7/logs/debug.log
2023-07-07 19:29:48,789 INFO    Thread-75 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192948-qmudgta7/logs/debug-internal.log
2023-07-07 19:29:48,789 INFO    Thread-75 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_192948-qmudgta7/logs/debug-internal.log
2023-07-07 19:29:48,789 INFO    Thread-75 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f355066cbe0>
2023-07-07 19:29:48,789 INFO    Thread-75 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f355066cbe0>
2023-07-07 19:29:48,790 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:29:48,790 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:29:48,790 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.9726158930262455e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:29:48,790 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.9726158930262455e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:29:48,791 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:29:48,791 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:29:48,791 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:29:48,791 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:29:48,804 INFO    Thread-75 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:29:48,804 INFO    Thread-75 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:29:48,814 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:29:48,814 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:29:48,833 INFO    Thread-75 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.9726158930262455e-05, 'weight_decay': 0.3}
2023-07-07 19:29:48,833 INFO    Thread-75 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.9726158930262455e-05, 'weight_decay': 0.3}
2023-07-07 19:29:48,838 INFO    Thread-75 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:29:48,838 INFO    Thread-75 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:29:48,838 INFO    Thread-75 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:29:48,838 INFO    Thread-75 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:29:48,838 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:29:48,838 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:29:48,849 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:29:48,849 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:29:49,184 INFO    Thread-75 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:29:49,184 INFO    Thread-75 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:29:49,344 INFO    Thread-75 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:29:49,344 INFO    Thread-75 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:29:49,344 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:29:49,344 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:29:55,894 INFO    Thread-75 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:29:55,894 INFO    Thread-75 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:29:55,895 INFO    Thread-75 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:29:55,895 INFO    Thread-75 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:29:55,895 INFO    Thread-75 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:29:55,895 INFO    Thread-75 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:29:55,895 INFO    Thread-75 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:29:55,895 INFO    Thread-75 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:29:55,897 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:29:55,897 INFO    Thread-75 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:29:57,751 INFO    Thread-75 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-29-57_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:29:57,751 INFO    Thread-75 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-29-57_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:30:26,968 INFO    Thread-75 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/qmudgta7
2023-07-07 19:30:26,968 INFO    Thread-75 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/qmudgta7
2023-07-07 19:30:26,969 INFO    Thread-75 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:30:26,969 INFO    Thread-75 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:30:26,970 INFO    Thread-75 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:30:26,970 INFO    Thread-75 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:30:26,970 INFO    Thread-75 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:30:26,970 INFO    Thread-75 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:30:26,970 INFO    Thread-75 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:30:26,970 INFO    Thread-75 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:30:26,970 INFO    Thread-75 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:30:26,970 INFO    Thread-75 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:30:26,971 INFO    Thread-75 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:30:26,971 INFO    Thread-75 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:30:30,467 INFO    Thread-75 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:30:30,467 INFO    Thread-75 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:30:30,468 INFO    Thread-75 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:30:30,468 INFO    Thread-75 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:30:30,480 INFO    Thread-75 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:30:30,480 INFO    Thread-75 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:30:36,224 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:30:36,224 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:30:36,224 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:30:36,224 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:30:36,224 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:30:36,224 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 't5im43l2', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-t5im43l2.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 't5im43l2', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-t5im43l2.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193036-t5im43l2/logs/debug.log
2023-07-07 19:30:36,225 INFO    Thread-78 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193036-t5im43l2/logs/debug.log
2023-07-07 19:30:36,226 INFO    Thread-78 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193036-t5im43l2/logs/debug-internal.log
2023-07-07 19:30:36,226 INFO    Thread-78 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193036-t5im43l2/logs/debug-internal.log
2023-07-07 19:30:36,226 INFO    Thread-78 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3550672320>
2023-07-07 19:30:36,226 INFO    Thread-78 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3550672320>
2023-07-07 19:30:36,227 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:30:36,227 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:30:36,227 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.0958242772017908e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:30:36,227 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.0958242772017908e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:30:36,227 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:30:36,227 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:30:36,227 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:30:36,227 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:30:36,240 INFO    Thread-78 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:30:36,240 INFO    Thread-78 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:30:36,249 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:30:36,249 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:30:36,268 INFO    Thread-78 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.0958242772017908e-05, 'weight_decay': 0.3}
2023-07-07 19:30:36,268 INFO    Thread-78 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.0958242772017908e-05, 'weight_decay': 0.3}
2023-07-07 19:30:36,273 INFO    Thread-78 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:30:36,273 INFO    Thread-78 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:30:36,273 INFO    Thread-78 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:30:36,273 INFO    Thread-78 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:30:36,273 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:30:36,273 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:30:36,284 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:30:36,284 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:30:36,589 INFO    Thread-78 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:30:36,589 INFO    Thread-78 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:30:36,747 INFO    Thread-78 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:30:36,747 INFO    Thread-78 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:30:36,748 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:30:36,748 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:30:42,721 INFO    Thread-78 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:30:42,721 INFO    Thread-78 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:30:42,722 INFO    Thread-78 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:30:42,722 INFO    Thread-78 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:30:42,722 INFO    Thread-78 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:30:42,722 INFO    Thread-78 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:30:42,722 INFO    Thread-78 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:30:42,722 INFO    Thread-78 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:30:42,724 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:30:42,724 INFO    Thread-78 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:30:44,519 INFO    Thread-78 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-30-44_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:30:44,519 INFO    Thread-78 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-30-44_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:31:28,345 INFO    Thread-78 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/t5im43l2
2023-07-07 19:31:28,345 INFO    Thread-78 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/t5im43l2
2023-07-07 19:31:28,346 INFO    Thread-78 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:31:28,346 INFO    Thread-78 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:31:28,346 INFO    Thread-78 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:31:28,346 INFO    Thread-78 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:31:28,346 INFO    Thread-78 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:31:28,346 INFO    Thread-78 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:31:28,347 INFO    Thread-78 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:31:28,347 INFO    Thread-78 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:31:28,347 INFO    Thread-78 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:31:28,347 INFO    Thread-78 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:31:28,347 INFO    Thread-78 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:31:28,347 INFO    Thread-78 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:31:32,626 INFO    Thread-78 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:31:32,626 INFO    Thread-78 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:31:32,628 INFO    Thread-78 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:31:32,628 INFO    Thread-78 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:31:32,640 INFO    Thread-78 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:31:32,640 INFO    Thread-78 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:31:37,555 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:31:37,555 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'ejpd6eol', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-ejpd6eol.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'ejpd6eol', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-ejpd6eol.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:31:37,556 INFO    Thread-81 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:31:37,557 INFO    Thread-81 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193137-ejpd6eol/logs/debug.log
2023-07-07 19:31:37,557 INFO    Thread-81 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193137-ejpd6eol/logs/debug.log
2023-07-07 19:31:37,557 INFO    Thread-81 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193137-ejpd6eol/logs/debug-internal.log
2023-07-07 19:31:37,557 INFO    Thread-81 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193137-ejpd6eol/logs/debug-internal.log
2023-07-07 19:31:37,557 INFO    Thread-81 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35506e0d00>
2023-07-07 19:31:37,557 INFO    Thread-81 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35506e0d00>
2023-07-07 19:31:37,558 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:31:37,558 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:31:37,559 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.710155866948203e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:31:37,559 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.710155866948203e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:31:37,559 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:31:37,559 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:31:37,559 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:31:37,559 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:31:37,572 INFO    Thread-81 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:31:37,572 INFO    Thread-81 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:31:37,582 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:31:37,582 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:31:37,601 INFO    Thread-81 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.710155866948203e-05, 'weight_decay': 0.3}
2023-07-07 19:31:37,601 INFO    Thread-81 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.710155866948203e-05, 'weight_decay': 0.3}
2023-07-07 19:31:37,610 INFO    Thread-81 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:31:37,610 INFO    Thread-81 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:31:37,610 INFO    Thread-81 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:31:37,610 INFO    Thread-81 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:31:37,611 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:31:37,611 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:31:37,622 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:31:37,622 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:31:37,888 INFO    Thread-81 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:31:37,888 INFO    Thread-81 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:31:38,044 INFO    Thread-81 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:31:38,044 INFO    Thread-81 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:31:38,045 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:31:38,045 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:31:43,737 INFO    Thread-81 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:31:43,737 INFO    Thread-81 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:31:43,738 INFO    Thread-81 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:31:43,738 INFO    Thread-81 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:31:43,738 INFO    Thread-81 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:31:43,738 INFO    Thread-81 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:31:43,738 INFO    Thread-81 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:31:43,738 INFO    Thread-81 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:31:43,740 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:31:43,740 INFO    Thread-81 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:31:45,374 INFO    Thread-81 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-31-45_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:31:45,374 INFO    Thread-81 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-31-45_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:32:16,707 INFO    Thread-81 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/ejpd6eol
2023-07-07 19:32:16,707 INFO    Thread-81 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/ejpd6eol
2023-07-07 19:32:16,709 INFO    Thread-81 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:32:16,709 INFO    Thread-81 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:32:16,709 INFO    Thread-81 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:32:16,709 INFO    Thread-81 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:32:16,709 INFO    Thread-81 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:32:16,709 INFO    Thread-81 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:32:16,709 INFO    Thread-81 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:32:16,709 INFO    Thread-81 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:32:16,710 INFO    Thread-81 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:32:16,710 INFO    Thread-81 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:32:16,710 INFO    Thread-81 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:32:16,710 INFO    Thread-81 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:32:45,844 INFO    Thread-81 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:32:45,844 INFO    Thread-81 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:32:45,845 INFO    Thread-81 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:32:45,845 INFO    Thread-81 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:32:45,857 INFO    Thread-81 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:32:45,857 INFO    Thread-81 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '1v2ep2k6', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-1v2ep2k6.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:32:49,752 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '1v2ep2k6', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-1v2ep2k6.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:32:49,753 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:32:49,753 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:32:49,753 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:32:49,753 INFO    Thread-84 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:32:49,753 INFO    Thread-84 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193249-1v2ep2k6/logs/debug.log
2023-07-07 19:32:49,753 INFO    Thread-84 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193249-1v2ep2k6/logs/debug.log
2023-07-07 19:32:49,753 INFO    Thread-84 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193249-1v2ep2k6/logs/debug-internal.log
2023-07-07 19:32:49,753 INFO    Thread-84 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193249-1v2ep2k6/logs/debug-internal.log
2023-07-07 19:32:49,754 INFO    Thread-84 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35506befe0>
2023-07-07 19:32:49,754 INFO    Thread-84 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35506befe0>
2023-07-07 19:32:49,755 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:32:49,755 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:32:49,755 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.3478840296179905e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:32:49,755 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.3478840296179905e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:32:49,755 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:32:49,755 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:32:49,755 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:32:49,755 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:32:49,768 INFO    Thread-84 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:32:49,768 INFO    Thread-84 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:32:49,777 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:32:49,777 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:32:49,796 INFO    Thread-84 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.3478840296179905e-05, 'weight_decay': 0.3}
2023-07-07 19:32:49,796 INFO    Thread-84 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.3478840296179905e-05, 'weight_decay': 0.3}
2023-07-07 19:32:49,801 INFO    Thread-84 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:32:49,801 INFO    Thread-84 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:32:49,801 INFO    Thread-84 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:32:49,801 INFO    Thread-84 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:32:49,802 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:32:49,802 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:32:49,813 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:32:49,813 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:33:01,196 INFO    Thread-84 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:33:01,196 INFO    Thread-84 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:33:01,367 INFO    Thread-84 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:33:01,367 INFO    Thread-84 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:33:01,367 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:33:01,367 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:33:06,900 INFO    Thread-84 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:33:06,900 INFO    Thread-84 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:33:06,901 INFO    Thread-84 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:33:06,901 INFO    Thread-84 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:33:06,901 INFO    Thread-84 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:33:06,901 INFO    Thread-84 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:33:06,901 INFO    Thread-84 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:33:06,901 INFO    Thread-84 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:33:06,903 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:33:06,903 INFO    Thread-84 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:33:08,729 INFO    Thread-84 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-33-08_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:33:08,729 INFO    Thread-84 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-33-08_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:33:52,522 INFO    Thread-84 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/1v2ep2k6
2023-07-07 19:33:52,522 INFO    Thread-84 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/1v2ep2k6
2023-07-07 19:33:52,524 INFO    Thread-84 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:33:52,524 INFO    Thread-84 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:33:52,524 INFO    Thread-84 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:33:52,524 INFO    Thread-84 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:33:52,524 INFO    Thread-84 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:33:52,524 INFO    Thread-84 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:33:52,524 INFO    Thread-84 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:33:52,524 INFO    Thread-84 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:33:52,525 INFO    Thread-84 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:33:52,525 INFO    Thread-84 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:33:52,525 INFO    Thread-84 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:33:52,525 INFO    Thread-84 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:33:57,666 INFO    Thread-84 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:33:57,666 INFO    Thread-84 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:33:57,667 INFO    Thread-84 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:33:57,667 INFO    Thread-84 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:33:57,679 INFO    Thread-84 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:33:57,679 INFO    Thread-84 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:34:04,401 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:34:04,401 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:34:04,401 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:34:04,401 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:34:04,401 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:34:04,401 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:34:04,401 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:34:04,401 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '3zhqsqor', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-3zhqsqor.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '3zhqsqor', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-3zhqsqor.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193404-3zhqsqor/logs/debug.log
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193404-3zhqsqor/logs/debug.log
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193404-3zhqsqor/logs/debug-internal.log
2023-07-07 19:34:04,402 INFO    Thread-87 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193404-3zhqsqor/logs/debug-internal.log
2023-07-07 19:34:04,403 INFO    Thread-87 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a8382290>
2023-07-07 19:34:04,403 INFO    Thread-87 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a8382290>
2023-07-07 19:34:04,403 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:34:04,403 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:34:04,404 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.901231089481695e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:34:04,404 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.901231089481695e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:34:04,404 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:34:04,404 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:34:04,404 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:34:04,404 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:34:04,416 INFO    Thread-87 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:34:04,416 INFO    Thread-87 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:34:04,428 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:34:04,428 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:34:04,447 INFO    Thread-87 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.901231089481695e-05, 'weight_decay': 0.3}
2023-07-07 19:34:04,447 INFO    Thread-87 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.901231089481695e-05, 'weight_decay': 0.3}
2023-07-07 19:34:04,454 INFO    Thread-87 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:34:04,454 INFO    Thread-87 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:34:04,454 INFO    Thread-87 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:34:04,454 INFO    Thread-87 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:34:04,454 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:34:04,454 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:34:04,465 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:34:04,465 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:34:04,724 INFO    Thread-87 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:34:04,724 INFO    Thread-87 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:34:04,894 INFO    Thread-87 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:34:04,894 INFO    Thread-87 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:34:04,894 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:34:04,894 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:34:11,627 INFO    Thread-87 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:34:11,627 INFO    Thread-87 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:34:11,628 INFO    Thread-87 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:34:11,628 INFO    Thread-87 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:34:11,628 INFO    Thread-87 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:34:11,628 INFO    Thread-87 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:34:11,628 INFO    Thread-87 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:34:11,628 INFO    Thread-87 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:34:11,630 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:34:11,630 INFO    Thread-87 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:34:13,352 INFO    Thread-87 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-34-13_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:34:13,352 INFO    Thread-87 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-34-13_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:35:18,683 INFO    Thread-87 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/3zhqsqor
2023-07-07 19:35:18,683 INFO    Thread-87 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/3zhqsqor
2023-07-07 19:35:18,685 INFO    Thread-87 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:35:18,685 INFO    Thread-87 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:35:18,685 INFO    Thread-87 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:35:18,685 INFO    Thread-87 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:35:18,685 INFO    Thread-87 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:35:18,685 INFO    Thread-87 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:35:18,685 INFO    Thread-87 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:35:18,685 INFO    Thread-87 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:35:18,686 INFO    Thread-87 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:35:18,686 INFO    Thread-87 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:35:18,686 INFO    Thread-87 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:35:18,686 INFO    Thread-87 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:35:21,928 INFO    Thread-87 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:35:21,928 INFO    Thread-87 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:35:21,929 INFO    Thread-87 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:35:21,929 INFO    Thread-87 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:35:21,941 INFO    Thread-87 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:35:21,941 INFO    Thread-87 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:35:25,693 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:35:25,693 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '2po1qo5f', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-2po1qo5f.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '2po1qo5f', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-2po1qo5f.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:35:25,694 INFO    Thread-90 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:35:25,695 INFO    Thread-90 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193525-2po1qo5f/logs/debug.log
2023-07-07 19:35:25,695 INFO    Thread-90 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193525-2po1qo5f/logs/debug.log
2023-07-07 19:35:25,695 INFO    Thread-90 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193525-2po1qo5f/logs/debug-internal.log
2023-07-07 19:35:25,695 INFO    Thread-90 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193525-2po1qo5f/logs/debug-internal.log
2023-07-07 19:35:25,695 INFO    Thread-90 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a8338460>
2023-07-07 19:35:25,695 INFO    Thread-90 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a8338460>
2023-07-07 19:35:25,696 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:35:25,696 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:35:25,696 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 5, 'learning_rate': 1.1564144587423063e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:35:25,696 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 5, 'learning_rate': 1.1564144587423063e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:35:25,696 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:35:25,696 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:35:25,696 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:35:25,696 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:35:25,708 INFO    Thread-90 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:35:25,708 INFO    Thread-90 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:35:25,718 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:35:25,718 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:35:25,737 INFO    Thread-90 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 5, 'learning_rate': 1.1564144587423063e-05, 'weight_decay': 0.3}
2023-07-07 19:35:25,737 INFO    Thread-90 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 5, 'learning_rate': 1.1564144587423063e-05, 'weight_decay': 0.3}
2023-07-07 19:35:25,742 INFO    Thread-90 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:35:25,742 INFO    Thread-90 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:35:25,742 INFO    Thread-90 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:35:25,742 INFO    Thread-90 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:35:25,742 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:35:25,742 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:35:25,753 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:35:25,753 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:35:26,061 INFO    Thread-90 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:35:26,061 INFO    Thread-90 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:35:26,225 INFO    Thread-90 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:35:26,225 INFO    Thread-90 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:35:26,225 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:35:26,225 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:35:32,863 INFO    Thread-90 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:35:32,863 INFO    Thread-90 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:35:32,864 INFO    Thread-90 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:35:32,864 INFO    Thread-90 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:35:32,864 INFO    Thread-90 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:35:32,864 INFO    Thread-90 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:35:32,864 INFO    Thread-90 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:35:32,864 INFO    Thread-90 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:35:32,866 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:35:32,866 INFO    Thread-90 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:35:34,836 INFO    Thread-90 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-35-34_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:35:34,836 INFO    Thread-90 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-35-34_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:37:13,823 INFO    Thread-90 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/2po1qo5f
2023-07-07 19:37:13,823 INFO    Thread-90 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/2po1qo5f
2023-07-07 19:37:13,824 INFO    Thread-90 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:37:13,824 INFO    Thread-90 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:37:13,824 INFO    Thread-90 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:37:13,824 INFO    Thread-90 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:37:13,824 INFO    Thread-90 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:37:13,824 INFO    Thread-90 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:37:13,824 INFO    Thread-90 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:37:13,824 INFO    Thread-90 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:37:13,825 INFO    Thread-90 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:37:13,825 INFO    Thread-90 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:37:13,825 INFO    Thread-90 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:37:13,825 INFO    Thread-90 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:37:17,354 INFO    Thread-90 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:37:17,354 INFO    Thread-90 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:37:17,355 INFO    Thread-90 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:37:17,355 INFO    Thread-90 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:37:17,367 INFO    Thread-90 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:37:17,367 INFO    Thread-90 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:37:23,113 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:37:23,113 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:37:23,113 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:37:23,113 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:37:23,113 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:37:23,113 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:37:23,113 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:37:23,113 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:37:23,114 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'uj2lfw4j', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-uj2lfw4j.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:37:23,114 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'uj2lfw4j', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-uj2lfw4j.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:37:23,114 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:37:23,114 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:37:23,114 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:37:23,114 INFO    Thread-93 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:37:23,114 INFO    Thread-93 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193723-uj2lfw4j/logs/debug.log
2023-07-07 19:37:23,114 INFO    Thread-93 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193723-uj2lfw4j/logs/debug.log
2023-07-07 19:37:23,115 INFO    Thread-93 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193723-uj2lfw4j/logs/debug-internal.log
2023-07-07 19:37:23,115 INFO    Thread-93 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193723-uj2lfw4j/logs/debug-internal.log
2023-07-07 19:37:23,115 INFO    Thread-93 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35517e1870>
2023-07-07 19:37:23,115 INFO    Thread-93 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35517e1870>
2023-07-07 19:37:23,116 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:37:23,116 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:37:23,116 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.9444370604052582e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:37:23,116 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.9444370604052582e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:37:23,116 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:37:23,116 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:37:23,116 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:37:23,116 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:37:23,129 INFO    Thread-93 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:37:23,129 INFO    Thread-93 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:37:23,138 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:37:23,138 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:37:23,167 INFO    Thread-93 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.9444370604052582e-05, 'weight_decay': 0.3}
2023-07-07 19:37:23,167 INFO    Thread-93 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.9444370604052582e-05, 'weight_decay': 0.3}
2023-07-07 19:37:23,174 INFO    Thread-93 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:37:23,174 INFO    Thread-93 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:37:23,174 INFO    Thread-93 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:37:23,174 INFO    Thread-93 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:37:23,174 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:37:23,174 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:37:23,187 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:37:23,187 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:37:23,484 INFO    Thread-93 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:37:23,484 INFO    Thread-93 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:37:23,642 INFO    Thread-93 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:37:23,642 INFO    Thread-93 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:37:23,642 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:37:23,642 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:37:29,835 INFO    Thread-93 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:37:29,835 INFO    Thread-93 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:37:29,836 INFO    Thread-93 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:37:29,836 INFO    Thread-93 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:37:29,836 INFO    Thread-93 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:37:29,836 INFO    Thread-93 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:37:29,836 INFO    Thread-93 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:37:29,836 INFO    Thread-93 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:37:29,838 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:37:29,838 INFO    Thread-93 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:37:31,829 INFO    Thread-93 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-37-31_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:37:31,829 INFO    Thread-93 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-37-31_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:38:23,282 INFO    Thread-93 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/uj2lfw4j
2023-07-07 19:38:23,282 INFO    Thread-93 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/uj2lfw4j
2023-07-07 19:38:23,284 INFO    Thread-93 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:38:23,284 INFO    Thread-93 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:38:23,284 INFO    Thread-93 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:38:23,284 INFO    Thread-93 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:38:23,284 INFO    Thread-93 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:38:23,284 INFO    Thread-93 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:38:23,284 INFO    Thread-93 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:38:23,284 INFO    Thread-93 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:38:23,285 INFO    Thread-93 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:38:23,285 INFO    Thread-93 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:38:23,285 INFO    Thread-93 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:38:23,285 INFO    Thread-93 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:38:28,644 INFO    Thread-93 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:38:28,644 INFO    Thread-93 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:38:28,645 INFO    Thread-93 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:38:28,645 INFO    Thread-93 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:38:28,657 INFO    Thread-93 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:38:28,657 INFO    Thread-93 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:38:34,609 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:38:34,609 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '36ngwzdb', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-36ngwzdb.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '36ngwzdb', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-36ngwzdb.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:38:34,610 INFO    Thread-96 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:38:34,611 INFO    Thread-96 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193834-36ngwzdb/logs/debug.log
2023-07-07 19:38:34,611 INFO    Thread-96 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193834-36ngwzdb/logs/debug.log
2023-07-07 19:38:34,611 INFO    Thread-96 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193834-36ngwzdb/logs/debug-internal.log
2023-07-07 19:38:34,611 INFO    Thread-96 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_193834-36ngwzdb/logs/debug-internal.log
2023-07-07 19:38:34,611 INFO    Thread-96 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35517e1150>
2023-07-07 19:38:34,611 INFO    Thread-96 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35517e1150>
2023-07-07 19:38:34,612 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:38:34,612 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:38:34,612 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.0275363350065345e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:38:34,612 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.0275363350065345e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:38:34,612 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:38:34,612 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:38:34,612 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:38:34,612 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:38:34,624 INFO    Thread-96 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:38:34,624 INFO    Thread-96 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:38:34,634 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:38:34,634 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:38:34,649 INFO    Thread-96 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.0275363350065345e-05, 'weight_decay': 0.3}
2023-07-07 19:38:34,649 INFO    Thread-96 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.0275363350065345e-05, 'weight_decay': 0.3}
2023-07-07 19:38:34,654 INFO    Thread-96 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:38:34,654 INFO    Thread-96 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:38:34,654 INFO    Thread-96 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:38:34,654 INFO    Thread-96 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:38:34,654 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:38:34,654 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:38:34,664 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:38:34,664 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:38:34,962 INFO    Thread-96 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:38:34,962 INFO    Thread-96 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:38:35,124 INFO    Thread-96 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:38:35,124 INFO    Thread-96 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:38:35,125 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:38:35,125 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:38:40,972 INFO    Thread-96 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:38:40,972 INFO    Thread-96 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:38:40,973 INFO    Thread-96 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:38:40,973 INFO    Thread-96 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:38:40,973 INFO    Thread-96 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:38:40,973 INFO    Thread-96 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:38:40,973 INFO    Thread-96 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:38:40,973 INFO    Thread-96 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:38:40,976 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:38:40,976 INFO    Thread-96 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:38:43,073 INFO    Thread-96 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-38-42_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:38:43,073 INFO    Thread-96 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-38-42_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:40:25,619 INFO    Thread-96 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/36ngwzdb
2023-07-07 19:40:25,619 INFO    Thread-96 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/36ngwzdb
2023-07-07 19:40:25,620 INFO    Thread-96 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:40:25,620 INFO    Thread-96 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:40:25,620 INFO    Thread-96 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:40:25,620 INFO    Thread-96 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:40:25,621 INFO    Thread-96 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:40:25,621 INFO    Thread-96 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:40:25,621 INFO    Thread-96 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:40:25,621 INFO    Thread-96 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:40:25,621 INFO    Thread-96 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:40:25,621 INFO    Thread-96 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:40:25,621 INFO    Thread-96 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:40:25,621 INFO    Thread-96 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:40:29,190 INFO    Thread-96 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:40:29,190 INFO    Thread-96 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:40:29,191 INFO    Thread-96 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:40:29,191 INFO    Thread-96 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:40:29,204 INFO    Thread-96 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:40:29,204 INFO    Thread-96 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:40:36,203 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:40:36,203 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:40:36,203 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:40:36,203 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:40:36,203 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:40:36,203 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'xi5ably8', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-xi5ably8.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'xi5ably8', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-xi5ably8.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194036-xi5ably8/logs/debug.log
2023-07-07 19:40:36,204 INFO    Thread-99 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194036-xi5ably8/logs/debug.log
2023-07-07 19:40:36,205 INFO    Thread-99 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194036-xi5ably8/logs/debug-internal.log
2023-07-07 19:40:36,205 INFO    Thread-99 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194036-xi5ably8/logs/debug-internal.log
2023-07-07 19:40:36,205 INFO    Thread-99 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35f027b2e0>
2023-07-07 19:40:36,205 INFO    Thread-99 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35f027b2e0>
2023-07-07 19:40:36,206 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:40:36,206 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:40:36,206 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 5, 'learning_rate': 1.9867049311627343e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:40:36,206 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 5, 'learning_rate': 1.9867049311627343e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:40:36,206 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:40:36,206 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:40:36,206 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:40:36,206 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:40:36,218 INFO    Thread-99 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:40:36,218 INFO    Thread-99 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:40:36,229 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:40:36,229 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:40:36,248 INFO    Thread-99 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 5, 'learning_rate': 1.9867049311627343e-05, 'weight_decay': 0.3}
2023-07-07 19:40:36,248 INFO    Thread-99 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 5, 'learning_rate': 1.9867049311627343e-05, 'weight_decay': 0.3}
2023-07-07 19:40:36,253 INFO    Thread-99 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:40:36,253 INFO    Thread-99 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:40:36,253 INFO    Thread-99 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:40:36,253 INFO    Thread-99 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:40:36,254 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:40:36,254 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:40:36,264 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:40:36,264 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:40:36,527 INFO    Thread-99 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:40:36,527 INFO    Thread-99 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:40:36,685 INFO    Thread-99 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:40:36,685 INFO    Thread-99 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:40:36,686 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:40:36,686 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:40:42,412 INFO    Thread-99 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:40:42,412 INFO    Thread-99 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:40:42,412 INFO    Thread-99 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:40:42,412 INFO    Thread-99 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:40:42,412 INFO    Thread-99 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:40:42,412 INFO    Thread-99 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:40:42,413 INFO    Thread-99 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:40:42,413 INFO    Thread-99 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:40:42,414 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:40:42,414 INFO    Thread-99 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:40:44,547 INFO    Thread-99 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-40-44_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:40:44,547 INFO    Thread-99 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-40-44_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:42:49,959 INFO    Thread-99 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/xi5ably8
2023-07-07 19:42:49,959 INFO    Thread-99 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/xi5ably8
2023-07-07 19:42:49,960 INFO    Thread-99 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:42:49,960 INFO    Thread-99 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:42:49,960 INFO    Thread-99 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:42:49,960 INFO    Thread-99 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:42:49,960 INFO    Thread-99 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:42:49,960 INFO    Thread-99 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:42:49,961 INFO    Thread-99 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:42:49,961 INFO    Thread-99 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:42:49,961 INFO    Thread-99 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:42:49,961 INFO    Thread-99 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:42:49,961 INFO    Thread-99 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:42:49,961 INFO    Thread-99 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:42:52,825 INFO    Thread-99 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:42:52,825 INFO    Thread-99 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:42:52,826 INFO    Thread-99 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:42:52,826 INFO    Thread-99 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:42:52,839 INFO    Thread-99 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:42:52,839 INFO    Thread-99 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:42:58,816 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:42:58,816 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '2xhx5dfv', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-2xhx5dfv.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '2xhx5dfv', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-2xhx5dfv.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:42:58,817 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:42:58,818 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:42:58,818 INFO    Thread-102 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:42:58,818 INFO    Thread-102 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194258-2xhx5dfv/logs/debug.log
2023-07-07 19:42:58,818 INFO    Thread-102 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194258-2xhx5dfv/logs/debug.log
2023-07-07 19:42:58,818 INFO    Thread-102 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194258-2xhx5dfv/logs/debug-internal.log
2023-07-07 19:42:58,818 INFO    Thread-102 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194258-2xhx5dfv/logs/debug-internal.log
2023-07-07 19:42:58,818 INFO    Thread-102 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3551604ac0>
2023-07-07 19:42:58,818 INFO    Thread-102 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3551604ac0>
2023-07-07 19:42:58,819 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:42:58,819 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:42:58,820 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.6178178686140594e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:42:58,820 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 2, 'learning_rate': 1.6178178686140594e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:42:58,820 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:42:58,820 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:42:58,820 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:42:58,820 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:42:58,833 INFO    Thread-102 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:42:58,833 INFO    Thread-102 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:42:58,842 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:42:58,842 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:42:58,862 INFO    Thread-102 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.6178178686140594e-05, 'weight_decay': 0.3}
2023-07-07 19:42:58,862 INFO    Thread-102 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 2, 'learning_rate': 1.6178178686140594e-05, 'weight_decay': 0.3}
2023-07-07 19:42:58,867 INFO    Thread-102 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:42:58,867 INFO    Thread-102 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:42:58,868 INFO    Thread-102 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:42:58,868 INFO    Thread-102 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:42:58,868 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:42:58,868 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:42:58,878 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:42:58,878 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:42:59,129 INFO    Thread-102 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:42:59,129 INFO    Thread-102 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:42:59,292 INFO    Thread-102 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:42:59,292 INFO    Thread-102 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:42:59,293 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:42:59,293 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:43:05,117 INFO    Thread-102 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:43:05,117 INFO    Thread-102 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:43:05,118 INFO    Thread-102 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:43:05,118 INFO    Thread-102 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:43:05,118 INFO    Thread-102 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:43:05,118 INFO    Thread-102 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:43:05,118 INFO    Thread-102 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:43:05,118 INFO    Thread-102 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:43:05,120 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:43:05,120 INFO    Thread-102 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:43:06,765 INFO    Thread-102 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-43-06_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:43:06,765 INFO    Thread-102 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-43-06_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:43:51,492 INFO    Thread-102 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/2xhx5dfv
2023-07-07 19:43:51,492 INFO    Thread-102 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/2xhx5dfv
2023-07-07 19:43:51,493 INFO    Thread-102 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:43:51,493 INFO    Thread-102 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:43:51,494 INFO    Thread-102 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:43:55,330 INFO    Thread-102 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:43:55,330 INFO    Thread-102 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:43:55,331 INFO    Thread-102 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:43:55,331 INFO    Thread-102 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:43:55,343 INFO    Thread-102 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:43:55,343 INFO    Thread-102 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'o9uczkgc', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-o9uczkgc.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:44:01,099 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'o9uczkgc', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-o9uczkgc.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:44:01,100 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:44:01,100 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:44:01,100 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:44:01,100 INFO    Thread-105 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:44:01,100 INFO    Thread-105 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194401-o9uczkgc/logs/debug.log
2023-07-07 19:44:01,100 INFO    Thread-105 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194401-o9uczkgc/logs/debug.log
2023-07-07 19:44:01,100 INFO    Thread-105 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194401-o9uczkgc/logs/debug-internal.log
2023-07-07 19:44:01,100 INFO    Thread-105 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194401-o9uczkgc/logs/debug-internal.log
2023-07-07 19:44:01,101 INFO    Thread-105 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3551776d40>
2023-07-07 19:44:01,101 INFO    Thread-105 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3551776d40>
2023-07-07 19:44:01,102 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:44:01,102 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:44:01,102 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.189896516709904e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:44:01,102 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.189896516709904e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:44:01,102 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:44:01,102 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:44:01,102 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:44:01,102 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:44:01,115 INFO    Thread-105 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:44:01,115 INFO    Thread-105 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:44:01,125 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:44:01,125 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:44:01,144 INFO    Thread-105 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.189896516709904e-05, 'weight_decay': 0.3}
2023-07-07 19:44:01,144 INFO    Thread-105 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.189896516709904e-05, 'weight_decay': 0.3}
2023-07-07 19:44:01,149 INFO    Thread-105 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:44:01,149 INFO    Thread-105 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:44:01,150 INFO    Thread-105 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:44:01,150 INFO    Thread-105 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:44:01,150 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:44:01,150 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:44:01,161 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:44:01,161 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:44:01,481 INFO    Thread-105 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:44:01,481 INFO    Thread-105 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:44:01,673 INFO    Thread-105 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:44:01,673 INFO    Thread-105 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:44:01,673 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:44:01,673 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:44:07,269 INFO    Thread-105 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:44:07,269 INFO    Thread-105 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:44:07,270 INFO    Thread-105 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:44:07,270 INFO    Thread-105 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:44:07,270 INFO    Thread-105 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:44:07,270 INFO    Thread-105 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:44:07,270 INFO    Thread-105 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:44:07,270 INFO    Thread-105 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:44:07,272 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:44:07,272 INFO    Thread-105 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:44:09,138 INFO    Thread-105 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-44-09_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:44:09,138 INFO    Thread-105 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-44-09_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:44:53,978 INFO    Thread-105 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/o9uczkgc
2023-07-07 19:44:53,978 INFO    Thread-105 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/o9uczkgc
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:44:53,980 INFO    Thread-105 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:44:53,981 INFO    Thread-105 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:44:53,981 INFO    Thread-105 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:44:57,473 INFO    Thread-105 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:44:57,473 INFO    Thread-105 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:44:57,474 INFO    Thread-105 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:44:57,474 INFO    Thread-105 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:44:57,486 INFO    Thread-105 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:44:57,486 INFO    Thread-105 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'zd9zw3yp', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-zd9zw3yp.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:45:02,402 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'zd9zw3yp', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-zd9zw3yp.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:45:02,403 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:45:02,403 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:45:02,403 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:45:02,403 INFO    Thread-108 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:45:02,403 INFO    Thread-108 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194502-zd9zw3yp/logs/debug.log
2023-07-07 19:45:02,403 INFO    Thread-108 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194502-zd9zw3yp/logs/debug.log
2023-07-07 19:45:02,403 INFO    Thread-108 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194502-zd9zw3yp/logs/debug-internal.log
2023-07-07 19:45:02,403 INFO    Thread-108 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194502-zd9zw3yp/logs/debug-internal.log
2023-07-07 19:45:02,404 INFO    Thread-108 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3551799ba0>
2023-07-07 19:45:02,404 INFO    Thread-108 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3551799ba0>
2023-07-07 19:45:02,404 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:45:02,404 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:45:02,405 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.3548128788871774e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:45:02,405 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.3548128788871774e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:45:02,405 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:45:02,405 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:45:02,405 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:45:02,405 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:45:02,417 INFO    Thread-108 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:45:02,417 INFO    Thread-108 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:45:02,426 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:45:02,426 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:45:02,445 INFO    Thread-108 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.3548128788871774e-05, 'weight_decay': 0.3}
2023-07-07 19:45:02,445 INFO    Thread-108 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.3548128788871774e-05, 'weight_decay': 0.3}
2023-07-07 19:45:02,450 INFO    Thread-108 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:45:02,450 INFO    Thread-108 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:45:02,451 INFO    Thread-108 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:45:02,451 INFO    Thread-108 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:45:02,451 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:45:02,451 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:45:02,461 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:45:02,461 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:45:02,753 INFO    Thread-108 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:45:02,753 INFO    Thread-108 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:45:02,909 INFO    Thread-108 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:45:02,909 INFO    Thread-108 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:45:02,910 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:45:02,910 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:45:08,588 INFO    Thread-108 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:45:08,588 INFO    Thread-108 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:45:08,588 INFO    Thread-108 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:45:08,588 INFO    Thread-108 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:45:08,589 INFO    Thread-108 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:45:08,589 INFO    Thread-108 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:45:08,589 INFO    Thread-108 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:45:08,589 INFO    Thread-108 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:45:08,590 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:45:08,590 INFO    Thread-108 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:45:10,708 INFO    Thread-108 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-45-10_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:45:10,708 INFO    Thread-108 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-45-10_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:46:11,075 INFO    Thread-108 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/zd9zw3yp
2023-07-07 19:46:11,075 INFO    Thread-108 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/zd9zw3yp
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:46:11,077 INFO    Thread-108 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:46:11,078 INFO    Thread-108 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:46:11,078 INFO    Thread-108 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:46:14,817 INFO    Thread-108 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:46:14,817 INFO    Thread-108 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:46:14,819 INFO    Thread-108 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:46:14,819 INFO    Thread-108 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:46:14,831 INFO    Thread-108 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:46:14,831 INFO    Thread-108 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '49mripvn', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-49mripvn.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:46:18,647 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': '49mripvn', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-49mripvn.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:46:18,648 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:46:18,648 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:46:18,648 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:46:18,648 INFO    Thread-111 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:46:18,648 INFO    Thread-111 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194618-49mripvn/logs/debug.log
2023-07-07 19:46:18,648 INFO    Thread-111 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194618-49mripvn/logs/debug.log
2023-07-07 19:46:18,648 INFO    Thread-111 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194618-49mripvn/logs/debug-internal.log
2023-07-07 19:46:18,648 INFO    Thread-111 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194618-49mripvn/logs/debug-internal.log
2023-07-07 19:46:18,649 INFO    Thread-111 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a83511b0>
2023-07-07 19:46:18,649 INFO    Thread-111 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a83511b0>
2023-07-07 19:46:18,649 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:46:18,649 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:46:18,650 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.040782907037013e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:46:18,650 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 3, 'learning_rate': 1.040782907037013e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:46:18,650 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:46:18,650 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:46:18,650 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:46:18,650 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:46:18,662 INFO    Thread-111 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:46:18,662 INFO    Thread-111 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:46:18,671 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:46:18,671 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:46:18,690 INFO    Thread-111 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.040782907037013e-05, 'weight_decay': 0.3}
2023-07-07 19:46:18,690 INFO    Thread-111 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 3, 'learning_rate': 1.040782907037013e-05, 'weight_decay': 0.3}
2023-07-07 19:46:18,696 INFO    Thread-111 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:46:18,696 INFO    Thread-111 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:46:18,696 INFO    Thread-111 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:46:18,696 INFO    Thread-111 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:46:18,696 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:46:18,696 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:46:18,707 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:46:18,707 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:46:19,011 INFO    Thread-111 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:46:19,011 INFO    Thread-111 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:46:19,174 INFO    Thread-111 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:46:19,174 INFO    Thread-111 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:46:19,175 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:46:19,175 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:46:24,928 INFO    Thread-111 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:46:24,928 INFO    Thread-111 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:46:24,929 INFO    Thread-111 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:46:24,929 INFO    Thread-111 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:46:24,929 INFO    Thread-111 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:46:24,929 INFO    Thread-111 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:46:24,930 INFO    Thread-111 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:46:24,930 INFO    Thread-111 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:46:24,932 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:46:24,932 INFO    Thread-111 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:46:26,776 INFO    Thread-111 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-46-26_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:46:26,776 INFO    Thread-111 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-46-26_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:47:18,361 INFO    Thread-111 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/49mripvn
2023-07-07 19:47:18,361 INFO    Thread-111 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/49mripvn
2023-07-07 19:47:18,362 INFO    Thread-111 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:47:18,362 INFO    Thread-111 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:47:18,362 INFO    Thread-111 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:47:18,362 INFO    Thread-111 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:47:18,362 INFO    Thread-111 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:47:18,362 INFO    Thread-111 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:47:18,362 INFO    Thread-111 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:47:18,362 INFO    Thread-111 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:47:18,363 INFO    Thread-111 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:47:18,363 INFO    Thread-111 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:47:18,363 INFO    Thread-111 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:47:18,363 INFO    Thread-111 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:47:21,250 INFO    Thread-111 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:47:21,250 INFO    Thread-111 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:47:21,251 INFO    Thread-111 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:47:21,251 INFO    Thread-111 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:47:21,262 INFO    Thread-111 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:47:21,262 INFO    Thread-111 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:47:24,969 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:47:24,969 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:47:24,969 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:47:24,969 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:47:24,969 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:47:24,969 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:47:24,969 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:47:24,969 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'urnwpode', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-urnwpode.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'urnwpode', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-urnwpode.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194724-urnwpode/logs/debug.log
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194724-urnwpode/logs/debug.log
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194724-urnwpode/logs/debug-internal.log
2023-07-07 19:47:24,970 INFO    Thread-114 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194724-urnwpode/logs/debug-internal.log
2023-07-07 19:47:24,971 INFO    Thread-114 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a8351300>
2023-07-07 19:47:24,971 INFO    Thread-114 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f35a8351300>
2023-07-07 19:47:24,971 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:47:24,971 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:47:24,972 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.6422027904832395e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:47:24,972 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 4, 'learning_rate': 1.6422027904832395e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:47:24,972 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:47:24,972 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:47:24,972 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:47:24,972 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:47:24,984 INFO    Thread-114 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:47:24,984 INFO    Thread-114 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:47:24,993 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:47:24,993 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:47:25,012 INFO    Thread-114 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.6422027904832395e-05, 'weight_decay': 0.3}
2023-07-07 19:47:25,012 INFO    Thread-114 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 4, 'learning_rate': 1.6422027904832395e-05, 'weight_decay': 0.3}
2023-07-07 19:47:25,017 INFO    Thread-114 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:47:25,017 INFO    Thread-114 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:47:25,017 INFO    Thread-114 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:47:25,017 INFO    Thread-114 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:47:25,017 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:47:25,017 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:47:25,028 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:47:25,028 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:47:25,349 INFO    Thread-114 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:47:25,349 INFO    Thread-114 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:47:25,535 INFO    Thread-114 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:47:25,535 INFO    Thread-114 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:47:25,535 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:47:25,535 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:47:31,139 INFO    Thread-114 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:47:31,139 INFO    Thread-114 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:47:31,140 INFO    Thread-114 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:47:31,140 INFO    Thread-114 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:47:31,140 INFO    Thread-114 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:47:31,140 INFO    Thread-114 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:47:31,140 INFO    Thread-114 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:47:31,140 INFO    Thread-114 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:47:31,142 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:47:31,142 INFO    Thread-114 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:47:33,002 INFO    Thread-114 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-47-32_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:47:33,002 INFO    Thread-114 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 4, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-47-32_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:48:31,992 INFO    Thread-114 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/urnwpode
2023-07-07 19:48:31,992 INFO    Thread-114 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/urnwpode
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:48:31,994 INFO    Thread-114 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:48:31,995 INFO    Thread-114 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:48:31,995 INFO    Thread-114 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:48:35,636 INFO    Thread-114 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:48:35,636 INFO    Thread-114 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:48:35,637 INFO    Thread-114 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:48:35,637 INFO    Thread-114 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:48:35,649 INFO    Thread-114 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:48:35,649 INFO    Thread-114 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:48:41,350 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:48:41,350 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Configure stats pid to 223
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/.config/wandb/settings
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from /home/jovyan/active-projects/textbook-question-generation/src/wandb/settings
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'pxuuit3o', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-pxuuit3o.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'ai-aloe', 'project': 'short answer scoring', 'root_dir': '/home/jovyan/active-projects/textbook-question-generation/src', 'run_id': 'pxuuit3o', 'sweep_param_path': '/home/jovyan/active-projects/textbook-question-generation/src/wandb/sweep-i7zmhhch/config-pxuuit3o.yaml', 'sweep_id': 'i7zmhhch'}
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:48:41,351 INFO    Thread-117 (_run_job):223 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-07 19:48:41,352 INFO    Thread-117 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194841-pxuuit3o/logs/debug.log
2023-07-07 19:48:41,352 INFO    Thread-117 (_run_job):223 [wandb_init.py:_log_setup():507] Logging user logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194841-pxuuit3o/logs/debug.log
2023-07-07 19:48:41,352 INFO    Thread-117 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194841-pxuuit3o/logs/debug-internal.log
2023-07-07 19:48:41,352 INFO    Thread-117 (_run_job):223 [wandb_init.py:_log_setup():508] Logging internal logs to /home/jovyan/active-projects/textbook-question-generation/src/wandb/run-20230707_194841-pxuuit3o/logs/debug-internal.log
2023-07-07 19:48:41,352 INFO    Thread-117 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3550673730>
2023-07-07 19:48:41,352 INFO    Thread-117 (_run_job):223 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f3550673730>
2023-07-07 19:48:41,353 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:48:41,353 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():547] calling init triggers
2023-07-07 19:48:41,354 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 5, 'learning_rate': 1.6108607293181748e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:48:41,354 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():554] wandb.init called with sweep_config: {'epochs': 5, 'learning_rate': 1.6108607293181748e-05, 'weight_decay': 0.3}
config: {}
2023-07-07 19:48:41,354 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:48:41,354 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():596] starting backend
2023-07-07 19:48:41,354 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:48:41,354 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():600] setting up manager
2023-07-07 19:48:41,366 INFO    Thread-117 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:48:41,366 INFO    Thread-117 (_run_job):223 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-07-07 19:48:41,376 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:48:41,376 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():606] backend started and connected
2023-07-07 19:48:41,396 INFO    Thread-117 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 5, 'learning_rate': 1.6108607293181748e-05, 'weight_decay': 0.3}
2023-07-07 19:48:41,396 INFO    Thread-117 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'epochs': 5, 'learning_rate': 1.6108607293181748e-05, 'weight_decay': 0.3}
2023-07-07 19:48:41,401 INFO    Thread-117 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:48:41,401 INFO    Thread-117 (_run_job):223 [wandb_run.py:_label_probe_notebook():1238] probe notebook
2023-07-07 19:48:41,401 INFO    Thread-117 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:48:41,401 INFO    Thread-117 (_run_job):223 [wandb_run.py:_label_probe_notebook():1248] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-07 19:48:41,401 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:48:41,401 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():700] updated telemetry
2023-07-07 19:48:41,412 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:48:41,412 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
2023-07-07 19:48:41,723 INFO    Thread-117 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:48:41,723 INFO    Thread-117 (_run_job):223 [wandb_run.py:_on_init():2177] communicating current version
2023-07-07 19:48:41,882 INFO    Thread-117 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:48:41,882 INFO    Thread-117 (_run_job):223 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-07-07 19:48:41,883 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:48:41,883 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():787] starting run threads in backend
2023-07-07 19:48:47,497 INFO    Thread-117 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:48:47,497 INFO    Thread-117 (_run_job):223 [wandb_run.py:_console_start():2158] atexit reg
2023-07-07 19:48:47,498 INFO    Thread-117 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:48:47,498 INFO    Thread-117 (_run_job):223 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
2023-07-07 19:48:47,498 INFO    Thread-117 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:48:47,498 INFO    Thread-117 (_run_job):223 [wandb_run.py:_redirect():2078] Wrapping output streams.
2023-07-07 19:48:47,498 INFO    Thread-117 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:48:47,498 INFO    Thread-117 (_run_job):223 [wandb_run.py:_redirect():2103] Redirects installed.
2023-07-07 19:48:47,500 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:48:47,500 INFO    Thread-117 (_run_job):223 [wandb_init.py:init():829] run started, returning control to user process
2023-07-07 19:48:49,338 INFO    Thread-117 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-48-49_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:48:49,338 INFO    Thread-117 (_run_job):223 [wandb_run.py:_config_callback():1286] config_cb None None {'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['MPNetForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'incorrect_answer', 1: 'correct_answer'}, 'label2id': {'incorrect_answer': 0, 'correct_answer': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/mpnet-base', 'transformers_version': '4.28.1', 'model_type': 'mpnet', 'vocab_size': 30527, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'relative_attention_num_buckets': 32, 'output_dir': 'results/hp-tuning', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluation_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'per_gpu_train_batch_size': 'None', 'per_gpu_eval_batch_size': 'None', 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': 2, 'eval_delay': 0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'results/hp-tuning/runs/Jul07_19-48-49_jupyter-wesley-2dmorris', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 1000, 'save_total_limit': 4, 'save_safetensors': False, 'save_on_each_node': False, 'no_cuda': False, 'use_mps_device': False, 'seed': 42, 'data_seed': 'None', 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': 'None', 'local_rank': -1, 'xpu_backend': 'None', 'tpu_num_cores': 'None', 'tpu_metrics_debug': False, 'debug': '[]', 'dataloader_drop_last': False, 'eval_steps': 1000, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'results/hp-tuning', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': 'None', 'load_best_model_at_end': False, 'metric_for_best_model': 'None', 'greater_is_better': 'None', 'ignore_data_skip': False, 'sharded_ddp': '[]', 'fsdp': '[]', 'fsdp_min_num_params': 0, 'fsdp_config': "{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}", 'fsdp_transformer_layer_cls_to_wrap': 'None', 'deepspeed': 'None', 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': 'None', 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': "['wandb']", 'ddp_find_unused_parameters': 'None', 'ddp_bucket_cap_mb': 'None', 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': 'None', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'gradient_checkpointing': False, 'include_inputs_for_metrics': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': 'None', 'push_to_hub_organization': 'None', 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': 'None', 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': 'None', 'torch_compile_mode': 'None', 'train_batch_size': 32, 'eval_batch_size': 32}
2023-07-07 19:50:06,302 INFO    Thread-117 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/pxuuit3o
2023-07-07 19:50:06,302 INFO    Thread-117 (_run_job):223 [wandb_run.py:_finish():1893] finishing run ai-aloe/short answer scoring/pxuuit3o
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [jupyter.py:save_history():445] not saving jupyter history
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [wandb_run.py:_atexit_cleanup():2127] got exitcode: 0
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:50:06,304 INFO    Thread-117 (_run_job):223 [wandb_run.py:_restore():2110] restore
2023-07-07 19:50:06,305 INFO    Thread-117 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:50:06,305 INFO    Thread-117 (_run_job):223 [wandb_run.py:_restore():2116] restore done
2023-07-07 19:50:10,164 INFO    Thread-117 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:50:10,164 INFO    Thread-117 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3469] rendering history
2023-07-07 19:50:10,165 INFO    Thread-117 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:50:10,165 INFO    Thread-117 (_run_job):223 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
2023-07-07 19:50:10,177 INFO    Thread-117 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
2023-07-07 19:50:10,177 INFO    Thread-117 (_run_job):223 [wandb_run.py:_footer_sync_info():3428] logging synced files
