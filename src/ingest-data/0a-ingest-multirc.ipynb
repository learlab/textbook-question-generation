{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df6e10d-c651-4396-81d2-82494cd1c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc18825-5bae-4aa0-80e0-198e78e9374c",
   "metadata": {},
   "source": [
    "## Load fresh MultiRC Dataset\n",
    "\n",
    "I want to train with the passage string and question string, which is not contained in the old multirc dataset at `../../bin/multirc_dataset.hf`\n",
    "\n",
    "I can't find any records of how the old multirc was constructed, and I can't reproduce the splits. It seems that candidate answers may have been generated with an LLM? Most of the reference answers overlap with those found in the MultiRC dataset, but some questions have the same correct answer, so this approach is not reliable.\n",
    "\n",
    "So I need to create a fresh version of the dataset. This dataset will not be suitable for testing previous models, as I cannot ensure that the test set has no overlap with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1f069b-7d2e-43c3-9c23-c73514eaca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multirc_dd = datasets.load_dataset(\"super_glue\", \"multirc\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace2461e-5186-4ac7-a628-de0229bfee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test set has no labels, so ignore it.\n",
    "multirc = pd.concat(\n",
    "    [ds.to_pandas() for ds in multirc_dd.values()][:2]\n",
    ")\n",
    "\n",
    "# Expand the `idx` column\n",
    "multirc[[\"passage_id\", \"question_id\", \"answer_id\"]] = multirc[\"idx\"].apply(pd.Series)\n",
    "multirc = multirc.rename(columns={\"paragraph\": \"passage\"})\n",
    "multirc = multirc.drop([\"idx\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc609c37-050e-4320-90f5-fba533828b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer\n",
       "Yes    303\n",
       "No     276\n",
       "3       58\n",
       "2       50\n",
       "4       43\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some reference answers appear across multiple questions\n",
    "multirc.groupby(\"answer\").size().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10426f78-f7d0-4e70-9b59-10ef8a6720f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "      <th>passage_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>answer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14748</th>\n",
       "      <td>Triumph and Disaster: The 20th century saw a s...</td>\n",
       "      <td>What resulted in the attack on the American fl...</td>\n",
       "      <td>The Japanese invasion of Britian</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>2795</td>\n",
       "      <td>14748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 passage  \\\n",
       "14748  Triumph and Disaster: The 20th century saw a s...   \n",
       "\n",
       "                                                question  \\\n",
       "14748  What resulted in the attack on the American fl...   \n",
       "\n",
       "                                 answer  label  passage_id  question_id  \\\n",
       "14748  The Japanese invasion of Britian      0         251         2795   \n",
       "\n",
       "       answer_id  \n",
       "14748      14748  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multirc.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e958abe-5e9f-4156-88a4-e487a0608e07",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b57555a7-bce5-41d0-8a77-ff636b783b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['passage', 'question', 'answer', 'label', 'passage_id', 'question_id', 'answer_id'],\n",
       "        num_rows: 21785\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['passage', 'question', 'answer', 'label', 'passage_id', 'question_id', 'answer_id'],\n",
       "        num_rows: 4770\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['passage', 'question', 'answer', 'label', 'passage_id', 'question_id', 'answer_id'],\n",
       "        num_rows: 5536\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partition_by_passage(df, train_size=0.7, dev_size=0.15, test_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Split a DataFrame into train, dev, and test sets while ensuring that all rows\n",
    "    with the same passage_id stay in the same partition.\n",
    "    \n",
    "    Returns a Hugging Face DatasetDict with train, dev, and test splits.\n",
    "    \"\"\"\n",
    "    # Get unique passage IDs\n",
    "    passage_ids = df['passage_id'].unique()\n",
    "    \n",
    "    # Create arrays for GroupShuffleSplit\n",
    "    X = np.arange(len(passage_ids))\n",
    "    \n",
    "    # First split: train vs (dev+test)\n",
    "    splitter_train = GroupShuffleSplit(n_splits=1, train_size=train_size, random_state=random_state)\n",
    "    train_idx, temp_idx = next(splitter_train.split(X, groups=passage_ids))\n",
    "    \n",
    "    train_ids = passage_ids[train_idx]\n",
    "    temp_ids = passage_ids[temp_idx]\n",
    "    \n",
    "    # Adjust sizes for the second split\n",
    "    dev_ratio = dev_size / (dev_size + test_size)\n",
    "    \n",
    "    # Second split: dev vs test (from the temp set)\n",
    "    splitter_dev = GroupShuffleSplit(n_splits=1, train_size=dev_ratio, random_state=random_state)\n",
    "    X_temp = np.arange(len(temp_ids))\n",
    "    dev_idx, test_idx = next(splitter_dev.split(X_temp, groups=temp_ids))\n",
    "    \n",
    "    dev_ids = temp_ids[dev_idx]\n",
    "    test_ids = temp_ids[test_idx]\n",
    "    \n",
    "    # Create the DatasetDict\n",
    "    dd = datasets.DatasetDict({\n",
    "        \"train\": datasets.Dataset.from_pandas(\n",
    "            df[df['passage_id'].isin(train_ids)], preserve_index=False\n",
    "        ),\n",
    "        \"dev\": datasets.Dataset.from_pandas(\n",
    "            df[df['passage_id'].isin(dev_ids)], preserve_index=False\n",
    "        ),\n",
    "        \"test\": datasets.Dataset.from_pandas(\n",
    "            df[df['passage_id'].isin(test_ids)], preserve_index=False\n",
    "        ),\n",
    "    })\n",
    "\n",
    "    return dd\n",
    "\n",
    "dd = partition_by_passage(multirc)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6e3ae2c-5096-49f2-a2ce-17520e452f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passage': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None),\n",
       " 'answer': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'passage_id': Value(dtype='int64', id=None),\n",
       " 'question_id': Value(dtype='int64', id=None),\n",
       " 'answer_id': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b22a2dcd-0e83-4f9c-b578-a05f862cd3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66eb9858d3b04cf0b79b38dc150cf100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/21785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bfed75016a4b4c94e2093c05c74176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4770 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7402cd487eae40e3864d09a32160efa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd.save_to_disk(\"../../data/multirc_contrastive_pairs.hf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
