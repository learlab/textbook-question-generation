{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386ad11e-a333-4d75-b31e-e5ba0445290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda_envs/metrics_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6130a5ec-a0d0-44a8-ad52-52e9eceb3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleurt_model = \"vaiibhavgupta/finetuned-bleurt-large\"\n",
    "mpnet_model = \"lear-lab/short-answer-classification\"\n",
    "modernbert_model = \"active-projects/itell-question-generation/results/modernbert_multirc\"\n",
    "bleurt_threshold = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2ec91a-9632-4264-9a7c-fc6c82e0a686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /home/jovyan/active-projects/itell-question-generation/src\n",
      " • multirc-v2-sequence-lengths-tobasum.ipynb\n",
      " • prompts\n",
      " • answer_probabilities.ipynb\n",
      " • compare_models_tobasum.py\n",
      " • compare_models_tobasum.ipynb\n",
      " • modernbert-vs-mpnet-vs-bleurt-tobasum.ipynb\n",
      " • eval-data.ipynb\n",
      " • cri_human_scoring_analysis_tobasum.ipynb\n",
      " • authentic-test-data\n",
      " • modernbert-vs-mpnet-vs-bleurt-tobasum-Copy1.ipynb\n",
      " • ingest-data\n",
      " • evaluate-q&a.ipynb\n",
      " • combined-eval.ipynb\n",
      " • __pycache__\n",
      " • eval\n",
      " • decoder-models\n",
      " • eval.ipynb\n",
      " • mpnet\n",
      " • aqag-irr.ipynb\n",
      " • .env\n",
      " • bleurt\n",
      " • longformer-training.ipynb\n",
      " • .ipynb_checkpoints\n",
      " • modernbert\n",
      " • modernbert-training-tobasum.ipynb\n",
      " • 3-compare-models.ipynb\n",
      " • modernbert-metrics-tobasum.ipynb\n",
      "\n",
      "Checking './results/modernbert_multirc':\n",
      " exists?  False\n",
      " is_dir? False\n",
      " is_file? False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Where am I right now?\n",
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "# 2) What’s in here?\n",
    "for name in os.listdir(\".\"):\n",
    "    print(\" •\", name)\n",
    "\n",
    "# 3) Check the path you’re using\n",
    "model_path = \"/home/jovyan/active-projects/itell-question-generation/results/modernbert_multirc\"  # whatever you set it to\n",
    "p = Path(model_path)\n",
    "print(f\"\\nChecking '{model_path}':\")\n",
    "print(\" exists? \", p.exists())\n",
    "print(\" is_dir?\", p.is_dir())\n",
    "print(\" is_file?\", p.is_file())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5ad0e8-6682-408c-b928-cd7c6ae1f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bleurt():\n",
    "    model_name = bleurt_model\n",
    "    threshold = bleurt_threshold\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=self.model_name,\n",
    "            device=\"cuda\",\n",
    "        )\n",
    "\n",
    "    def __call__(self, candidate: str, reference: str) -> int:\n",
    "        sequence = f\"{candidate}[SEP]{reference}\"\n",
    "\n",
    "        result = self.classifier(sequence)\n",
    "        score = result[0][\"score\"]\n",
    "\n",
    "        return 1 if score > self.threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22763d7d-5d2c-4f73-b3c4-dbac5fb2314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mpnet():\n",
    "    model_name = mpnet_model\n",
    "    revision = \"77b846ec4606bfcfdf913888d7f0ab51f977a579\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=self.model_name,\n",
    "            revision=self.revision,\n",
    "            device=\"cuda\",\n",
    "            )\n",
    "\n",
    "    def __call__(self, candidate: str, reference: str) -> int:\n",
    "        sequence = f\"{candidate}</s>{reference}\"\n",
    "\n",
    "        result = self.classifier(sequence)\n",
    "        label = result[0][\"label\"]\n",
    "\n",
    "        return 1 if label == \"correct_answer\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e0897d-3a63-4592-803c-bbf8e314b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "class ModernBERT():\n",
    "    model_name = modernbert_model\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=self.model_name,\n",
    "            device=\"cuda\",\n",
    "            )\n",
    "\n",
    "    def __call__(self, candidate: str, reference: str) -> int:\n",
    "        sequence = f\"{candidate}</s>{reference}\"\n",
    "\n",
    "        result = self.classifier(sequence)\n",
    "        label = result[0][\"label\"]\n",
    "\n",
    "        return 1 if label == \"correct_answer\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f3c58ac-3bd7-42e5-bb4f-6d2d39f25407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Device set to use cuda\n",
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "mpnet = Mpnet()\n",
    "bleurt = Bleurt()\n",
    "modernBERT = ModernBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04017245-b580-414a-a283-ef2c0702ce34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Device set to use cuda\n",
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipes = {\n",
    "    \"Mpnet_pipe\": Mpnet(),\n",
    "    \"Bleurt_pipe\": Bleurt(),\n",
    "    \"ModernBERT_pipe\": ModernBERT()\n",
    "}\n",
    "\n",
    "def evaluate_all_models(dataset, models, label_key=\"labels\"):\n",
    "    texts = []\n",
    "    true_labels = []\n",
    "    preds_dict = {name: [] for name in models.keys()}\n",
    "\n",
    "    for example in dataset[\"test\"]:\n",
    "        text = example[\"text\"]\n",
    "        texts.append(input_text)\n",
    "\n",
    "        true_label = example[label_key]\n",
    "        true_labels.append(true_label)\n",
    "\n",
    "        for name, pipe in pipes.items():\n",
    "            pred_label = pipe.predict(student_response, reference) \n",
    "            preds_dict[name].append(pred)\n",
    "\n",
    "    results_dict = {\n",
    "        \"input_text\": texts,\n",
    "        \"true_label\": true_labels\n",
    "    }\n",
    "\n",
    "    for name, preds in preds_dict.items():\n",
    "        results_dict[f\"{name}_pred\"] = preds\n",
    "\n",
    "    return pd.DataFrame(results_dict)\n",
    "\n",
    "# df_predictions = evaluate_all_models(ds, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d04f30d8-c3e9-4253-b7b4-35cd116136db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnet(\"This a strong answer to the question\", \"This is a reference answer to the question\")  # Scored incorrect (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9964cb6c-89d2-41c3-b0f4-b415934ff2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleurt(\"This a strong answer to the question\", \"This is a reference answer to the question\")  # Scored correct (1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metrics_env]",
   "language": "python",
   "name": "conda-env-metrics_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
