{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213549ea-55e2-420d-bafb-813943eba1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import (Trainer, TrainingArguments, DataCollatorWithPadding,\n",
    "                          AutoTokenizer, AutoModelForSequenceClassification)\n",
    "from sklearn import metrics\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5447c48-3116-4167-a44a-86488244c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"answerdotai/ModernBERT-base\"\n",
    "dataset_path = \"../../data/race_multirc_contrastive_pairs.hf\"\n",
    "output_dir = \"../../results/modernbert-race-multirc\"\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 8\n",
    "learning_rate = 3e-5\n",
    "seed = 42\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f88be84-8275-4e98-ac36-538441e73fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=2,\n",
    "        label2id={\"incorrect\": 0, \"correct\": 1},\n",
    "        id2label={0: \"incorrect\", 1: \"correct\"},\n",
    "    )   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73eaeaf1-06fe-4aca-ace1-e365eb35bafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb9389073c34db69f2e2eaf18849ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/146675 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f137be328043a185a4a2fa5e4c252b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11672 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6631c693eb4e7db55b510aa3aa022f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12532 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(example):\n",
    "    input_str = f'{example[\"passage\"]}\\n\\n{example[\"question\"]}\\n\\n{example[\"answer\"]}'\n",
    "    return tokenizer(input_str, truncation=True)\n",
    "\n",
    "dd = datasets.DatasetDict.load_from_disk(dataset_path)\n",
    "dd = dd.map(\n",
    "    preprocess_function,\n",
    "    batched=False,\n",
    "    remove_columns=[\n",
    "        \"passage\", \"question\", \"answer\",\n",
    "        \"passage_id\", \"question_id\", \"answer_id\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9296103c-39e4-42cf-afbc-90f1d14879e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 146675\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 11672\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 12532\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eabb216-7b1c-4d7e-a588-7ba9b57ab5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    eval_pred : tuple\n",
    "        A tuple of (logits, labels) provided by the Hugging Face Trainer.\n",
    "        - logits: numpy array of shape (n_samples, 2) for binary classification\n",
    "        - labels: numpy array of shape (n_samples,)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing various metrics:\n",
    "        - accuracy: Accuracy score\n",
    "        - precision: Precision score\n",
    "        - recall: Recall score\n",
    "        - f1: F1 score\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = metrics.accuracy_score(labels, preds)\n",
    "    \n",
    "    # Calculate precision, recall, f1\n",
    "    precision, recall, f1, _ = metrics.precision_recall_fscore_support(\n",
    "        labels, \n",
    "        preds, \n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    \n",
    "    # Return metrics dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d21d14-6eec-44bd-acb6-472973946553",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "677b3931-eb6c-4830-a9e6-c7ed20b2f125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[-0.3040,  0.0477]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def test_modernbert(ds):\n",
    "    \"\"\"\n",
    "    Make sure ModernBert model is not returning NaNs.\n",
    "\n",
    "    If the logits tensor has NaN values, there is a dependency issue.\n",
    "    \"\"\"\n",
    "    model = model_init().to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch = ds[\"train\"][0]\n",
    "        input_ids = torch.tensor([batch[\"input_ids\"]])\n",
    "        attention_mask=torch.tensor([batch[\"attention_mask\"]])\n",
    "        token_type_ids=torch.zeros_like(input_ids)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids.to(\"cuda\"),\n",
    "            attention_mask=attention_mask.to(\"cuda\"),\n",
    "            token_type_ids=token_type_ids.to(\"cuda\")\n",
    "        )\n",
    "        \n",
    "        \n",
    "    return outputs\n",
    "\n",
    "outputs = test_modernbert(dd)\n",
    "print(\"Logits:\", outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7beca55-2651-4980-9b46-a30f22fa625e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='281128' max='293352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [281128/293352 8:18:43 < 21:41, 9.39 it/s, Epoch 7.67/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.695600</td>\n",
       "      <td>0.696167</td>\n",
       "      <td>0.476268</td>\n",
       "      <td>0.238134</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.322616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.691129</td>\n",
       "      <td>0.523732</td>\n",
       "      <td>0.261866</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.343717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.694403</td>\n",
       "      <td>0.497515</td>\n",
       "      <td>0.528015</td>\n",
       "      <td>0.514220</td>\n",
       "      <td>0.437131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.698193</td>\n",
       "      <td>0.523732</td>\n",
       "      <td>0.261866</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.343717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.677412</td>\n",
       "      <td>0.552947</td>\n",
       "      <td>0.550584</td>\n",
       "      <td>0.549655</td>\n",
       "      <td>0.548837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.679400</td>\n",
       "      <td>0.687225</td>\n",
       "      <td>0.560315</td>\n",
       "      <td>0.585556</td>\n",
       "      <td>0.543819</td>\n",
       "      <td>0.489091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.679800</td>\n",
       "      <td>0.712365</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.563328</td>\n",
       "      <td>0.560929</td>\n",
       "      <td>0.558779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    bf16 = True, # bfloat16 training \n",
    "    optim = \"adamw_torch_fused\",\n",
    "    num_train_epochs = num_epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    learning_rate = learning_rate,\n",
    "    logging_dir = f'../bin/logs/modernbert-multirc',\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    seed = seed,\n",
    "    log_level = 'error',  \n",
    "    disable_tqdm = False, \n",
    "    report_to = \"none\", # Disable WandB reporting\n",
    ") \n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init = model_init,\n",
    "    args = training_args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset = dd[\"train\"],\n",
    "    eval_dataset = dd[\"dev\"],\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e651225-6bb5-4c15-88ef-e05cb94ad0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../../results/modernbert_race_multirc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41a52b-881b-4dd0-a22c-fd73fc0df44d",
   "metadata": {},
   "source": [
    "# Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82aa6b69-e758-4212-9710-c402ab3427f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'correct', 'score': 0.9971210360527039}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    " \n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\", \n",
    "    model=\"../../results/modernbert_race_multirc\",\n",
    "    tokenizer=model_name_or_path,\n",
    "    device=0,\n",
    ")\n",
    " \n",
    "sample = \"Smoking is bad for your health.\"\n",
    " \n",
    "classifier(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
