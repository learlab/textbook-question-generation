{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25593a32-ed10-42ae-938f-98549f4ce10d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "#import wandb\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (Trainer, TrainingArguments, DataCollatorWithPadding,\n",
    "                          AutoTokenizer, AutoModelForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d39bcd8e-5b78-42c4-bd92-edaf7e4259bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"microsoft/mpnet-base\"\n",
    "dataset_path = '../bin/multirc_dataset.hf'\n",
    "output_dir = 'results/hp-tuning'\n",
    "model_max_length = 512\n",
    "eval_steps = 1000\n",
    "eval_accumulation_steps = 2\n",
    "save_total_limit = 4\n",
    "batch_size = 32\n",
    "num_epochs = 8\n",
    "learning_rate = 3e-05\n",
    "seed = 42\n",
    "metric = 'accuracy'\n",
    "entity = 'ai-aloe'\n",
    "project_name = 'short answer scoring'\n",
    "\n",
    "id2label = {0: \"incorrect_answer\", 1: \"correct_answer\"}\n",
    "label2id = {\"incorrect_answer\": 0, \"correct_answer\": 1}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    max_length=model_max_length,\n",
    "    )\n",
    "\n",
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,\n",
    "                                                               num_labels=2,\n",
    "                                                               id2label=id2label,\n",
    "                                                               label2id=label2id)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5b577b9-82e6-4e79-b9e2-02ac160794e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c74aebde6ad4897b6ed9842bf24a8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=True, truncation=True)\n",
    "    \n",
    "ds = DatasetDict.load_from_disk(dataset_path)\n",
    "ds = ds.map(preprocess_function, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adb69fa9-9d7a-4c7d-8728-236085421da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['index', 'text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 19170\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['index', 'text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4080\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['index', 'text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3962\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e7a94cb-085a-4a13-9c34-8a666c5139a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe26ce5d-9aba-4b42-92da-44b272eb794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "376a9939-1fae-45f3-b9e4-81872473802e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/4800 : < :, Epoch 0.00/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 47.54 GiB total capacity; 21.02 GiB already allocated; 201.25 MiB free; 21.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 40\u001b[0m\n\u001b[1;32m     29\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     30\u001b[0m     model_init \u001b[38;5;241m=\u001b[39m model_init,\n\u001b[1;32m     31\u001b[0m     args \u001b[38;5;241m=\u001b[39m training_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\u001b[39;00m\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1892\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1895\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1896\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1898\u001b[0m ):\n\u001b[1;32m   1899\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/trainer.py:2776\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2776\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2779\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/trainer.py:2801\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2800\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2801\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:718\u001b[0m, in \u001b[0;36mMPNetForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    716\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 718\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmpnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    729\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:551\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    550\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 551\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    560\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:341\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    339\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 341\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:300\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    293\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    299\u001b[0m ):\n\u001b[0;32m--> 300\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    308\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:241\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    234\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    240\u001b[0m ):\n\u001b[0;32m--> 241\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(self_outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m hidden_states)\n\u001b[1;32m    249\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:190\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 190\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m attention_probs \u001b[38;5;241m*\u001b[39m head_mask\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/wes_main/lib/python3.11/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 47.54 GiB total capacity; 21.02 GiB already allocated; 201.25 MiB free; 21.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = f'./results/mpnet_checkpoints',\n",
    "    optim = 'adamw_torch',\n",
    "    num_train_epochs = num_epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    weight_decay = 0.01,\n",
    "    learning_rate = learning_rate,\n",
    "    logging_dir = f'./logs/content',\n",
    "    save_total_limit = 10,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'accuracy',\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\", \n",
    "    greater_is_better = True,\n",
    "    seed=seed,\n",
    "    log_level = 'error',  \n",
    "    disable_tqdm = False, \n",
    ") \n",
    "\n",
    "    # Call the Trainer\n",
    "trainer = Trainer(\n",
    "    model_init = model_init,\n",
    "    args = training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset = ds['train'],\n",
    "    eval_dataset = ds['valid'],\n",
    "    compute_metrics = compute_metrics\n",
    "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188c5a1d-283f-411e-8bb4-1babeb5c15bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.091878175735474\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "preds, labels, metrics= trainer.predict(ds['test'])\n",
    "predictions = np.argmax(preds, axis=1)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f4a3df-2867-476a-8720-bdfd12a311ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(labels, predictions)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['incorrect', 'correct'])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.title('Predicted and True Classifications of Correct and Incorrect Answers (MPnet)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23e25146-95ad-40e7-8e4e-8e72d1f4552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      2240\n",
      "           1       0.80      0.76      0.78      1722\n",
      "\n",
      "    accuracy                           0.81      3962\n",
      "   macro avg       0.81      0.81      0.81      3962\n",
      "weighted avg       0.81      0.81      0.81      3962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76c762e9-caf1-4a8a-88b6-a5a1d823338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../bin/mpnet_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6758da99-6207-4d1a-9408-4dacc11fb4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378378378378378"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.cohen_kappa_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3637db10-feba-483f-bdbc-87e8fa19cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from time import perf_counter\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "preds = []\n",
    "times = []\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../bin/mpnet_multimc_classifier\").to(device)\n",
    "for text in ds['test']['text']:\n",
    "    start_time = perf_counter()\n",
    "    inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    preds.append(model.config.id2label[predicted_class_id])\n",
    "    times.append(perf_counter()-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ca77810-592b-4bee-b9ea-c605732a2598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds['test'].to_pandas()\n",
    "df['preds']=preds\n",
    "df['times']=times\n",
    "df.to_csv('mpnet-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d66046d8-e747-4e3d-b845-ff04afe39227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  correct_answer       0.80      0.76      0.78      1722\n",
      "incorrect_answer       0.82      0.85      0.84      2240\n",
      "\n",
      "        accuracy                           0.81      3962\n",
      "       macro avg       0.81      0.81      0.81      3962\n",
      "    weighted avg       0.81      0.81      0.81      3962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for x in ds['test']['labels']:\n",
    "    if x == 1:\n",
    "        labels.append('correct_answer' )\n",
    "    else: \n",
    "        labels.append('incorrect_answer') \n",
    "\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(metrics.classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44dd3524-430f-409a-95df-98a07f254504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608415e0e3444d36805a46063f65a0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcc9afc1-a5ee-4569-a9c3-a27e7ae380eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/tiedaar/short-answer-classification/commit/30da339a79dd1334063ce2f5ba64d6df1d676055', commit_message='Upload tokenizer', commit_description='', oid='30da339a79dd1334063ce2f5ba64d6df1d676055', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"short-answer-classification\")\n",
    "tokenizer.push_to_hub(\"short-answer-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46942ad-a5c3-4a55-a171-5f7b92720d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsection_num</th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>mpnet_response</th>\n",
       "      <th>bleurt_response</th>\n",
       "      <th>correct_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subsection_num, source, question, answer, mpnet_response, bleurt_response, correct_response]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "dataset = load_dataset(\"tiedaar/question_scoring_stresstest\")['train'].to_pandas()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a648ab-acaa-44f1-8ad0-35d50a4ce948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ABC', 'Hello World', '2023-05-10 04:53:08.014230'],\n",
       "        num_rows: 202\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e35e75-40c2-4884-bc2f-fc2807527579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
