{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664cf36-93b1-4145-bd56-233c4d553c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade Pytorch & other libraries\n",
    "%pip install --upgrade --quiet \\\n",
    "    torch torchvision torchaudio \\\n",
    "    transformers accelerate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213549ea-55e2-420d-bafb-813943eba1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import (Trainer, TrainingArguments, DataCollatorWithPadding,\n",
    "                          AutoTokenizer, AutoModelForSequenceClassification)\n",
    "from sklearn import metrics\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5447c48-3116-4167-a44a-86488244c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"answerdotai/ModernBERT-base\"\n",
    "dataset_path = \"../bin/multirc_dataset.hf\"\n",
    "output_dir = \"../bin/modernbert-multirc\"\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 8\n",
    "learning_rate = 3e-5\n",
    "seed = 42\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f88be84-8275-4e98-ac36-538441e73fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=2,\n",
    "        label2id={\"incorrect\": 0, \"correct\": 1},\n",
    "        id2label={0: \"incorrect\", 1: \"correct\"},\n",
    "    )   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d97659-c6b9-44f5-b4ac-a7ebe7e37d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcf2d7cf0e240f7b8e64c34b2b6eb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "ds = datasets.DatasetDict.load_from_disk(dataset_path)\n",
    "ds = ds.map(preprocess_function, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23025100-b6bf-4879-a392-527ee722a553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 1, 0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"][\"labels\"][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9296103c-39e4-42cf-afbc-90f1d14879e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['index', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 19170\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['index', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4080\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['index', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3962\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eabb216-7b1c-4d7e-a588-7ba9b57ab5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    eval_pred : tuple\n",
    "        A tuple of (logits, labels) provided by the Hugging Face Trainer.\n",
    "        - logits: numpy array of shape (n_samples, 2) for binary classification\n",
    "        - labels: numpy array of shape (n_samples,)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing various metrics:\n",
    "        - accuracy: Accuracy score\n",
    "        - precision: Precision score\n",
    "        - recall: Recall score\n",
    "        - f1: F1 score\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = metrics.accuracy_score(labels, preds)\n",
    "    \n",
    "    # Calculate precision, recall, f1\n",
    "    precision, recall, f1, _ = metrics.precision_recall_fscore_support(\n",
    "        labels, \n",
    "        preds, \n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    \n",
    "    # Return metrics dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d21d14-6eec-44bd-acb6-472973946553",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "677b3931-eb6c-4830-a9e6-c7ed20b2f125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[0.1258, 0.6800]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def test_modernbert(ds):\n",
    "    \"\"\"\n",
    "    Make sure ModernBert model is not returning NaNs.\n",
    "\n",
    "    If the logits tensor has NaN values, there is a dependency issue.\n",
    "    \"\"\"\n",
    "    model = model_init().to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch = ds[\"train\"][0]\n",
    "        input_ids = torch.tensor([batch[\"input_ids\"]])\n",
    "        attention_mask=torch.tensor([batch[\"attention_mask\"]])\n",
    "        token_type_ids=torch.zeros_like(input_ids)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids.to(\"cuda\"),\n",
    "            attention_mask=attention_mask.to(\"cuda\"),\n",
    "            token_type_ids=token_type_ids.to(\"cuda\")\n",
    "        )\n",
    "        \n",
    "        \n",
    "    return outputs\n",
    "\n",
    "outputs = test_modernbert(ds)\n",
    "print(\"Logits:\", outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7beca55-2651-4980-9b46-a30f22fa625e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30384' max='38344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30384/38344 51:35 < 13:31, 9.81 it/s, Epoch 6.34/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>0.540866</td>\n",
       "      <td>0.785294</td>\n",
       "      <td>0.786131</td>\n",
       "      <td>0.781233</td>\n",
       "      <td>0.782530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.448900</td>\n",
       "      <td>0.639280</td>\n",
       "      <td>0.801225</td>\n",
       "      <td>0.802046</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.798832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0.829146</td>\n",
       "      <td>0.795098</td>\n",
       "      <td>0.796540</td>\n",
       "      <td>0.790833</td>\n",
       "      <td>0.792295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.274600</td>\n",
       "      <td>1.102795</td>\n",
       "      <td>0.798284</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.794537</td>\n",
       "      <td>0.795834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>1.543763</td>\n",
       "      <td>0.789706</td>\n",
       "      <td>0.788580</td>\n",
       "      <td>0.788221</td>\n",
       "      <td>0.788388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>1.587519</td>\n",
       "      <td>0.795343</td>\n",
       "      <td>0.796088</td>\n",
       "      <td>0.791579</td>\n",
       "      <td>0.792857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    bf16 = True, # bfloat16 training \n",
    "    optim = \"adamw_torch_fused\",\n",
    "    num_train_epochs = num_epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    learning_rate = learning_rate,\n",
    "    logging_dir = f'../bin/logs/modernbert-multirc',\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"no\", \n",
    "    seed = seed,\n",
    "    log_level = 'error',  \n",
    "    disable_tqdm = False, \n",
    "    report_to = \"none\", # Disable WandB reporting\n",
    ") \n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init = model_init,\n",
    "    args = training_args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset = ds[\"train\"],\n",
    "    eval_dataset = ds[\"valid\"],\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e651225-6bb5-4c15-88ef-e05cb94ad0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../results/modernbert_multirc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41a52b-881b-4dd0-a22c-fd73fc0df44d",
   "metadata": {},
   "source": [
    "# Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82aa6b69-e758-4212-9710-c402ab3427f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'correct', 'score': 0.9971210360527039}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    " \n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\", \n",
    "    model=\"../results/modernbert_multirc\",\n",
    "    tokenizer=model_name_or_path,\n",
    "    device=0,\n",
    ")\n",
    " \n",
    "sample = \"Smoking is bad for your health.\"\n",
    " \n",
    "classifier(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
