{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20125803-d15f-4605-8008-4506ec1a344d",
   "metadata": {},
   "source": [
    "# Train ModernBERT on Pseudo-labeled Data\n",
    "\n",
    "Pseudo-labeled data comes from two sources:\n",
    "- MultiRC, pseudo-labeled by GPT5\n",
    "- Authentic iTELL data, pseudo-labeled by o3-mini\n",
    "\n",
    "Humans have labeled a non-overlapping portion of the authentic iTELL data. This will be our held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738f2e78-d799-4fd6-acf5-e8280aab645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import (Trainer, TrainingArguments, DataCollatorWithPadding,\n",
    "                          AutoTokenizer, AutoModelForSequenceClassification)\n",
    "from sklearn import metrics\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5780c7c3-769e-4753-bb46-f9d38a92dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"answerdotai/ModernBERT-base\"\n",
    "output_dir = \"../../results/modernbert-multirc-pseudo-labeled\"\n",
    "\n",
    "# Training/Validation Data:\n",
    "datadict_path = \"../../data/authentic-03-scores-multirc-gpt5-scores.hf\" # The prepared training and validation data\n",
    "multirc_path = \"../../data/multirc-data-w-gpt5-scores.csv\" # A subsample of MultiRC, scored by GPT 5\n",
    "authentic_path = \"../../data/authentic_train_data.csv\" # Authentic data from iTELL, scored by o3-mini using the same rubric/prompt\n",
    "\n",
    "# Test Data:\n",
    "test_data_path = \"../../data/authentic_test_data.csv\" # Authentic data from iTELL, scored by the iTELL development team\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 8\n",
    "learning_rate = 3e-5\n",
    "seed = 42\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb9729-21de-4f83-b029-ffc261911d8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Construct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3042bc-0ffe-4d59-8030-cefab04705f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A flood occurs when a river overflows its bank...</td>\n",
       "      <td>What forms the raised strip near the edge of a...</td>\n",
       "      <td>Sandy desert</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Force is a vector. What then is a vector? Thin...</td>\n",
       "      <td>What two pieces of information does a vector p...</td>\n",
       "      <td>Motion and distance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madrid, Spain (CNN) -- Relatives of a woman ki...</td>\n",
       "      <td>Where was the Spanish MD82 bound for when the ...</td>\n",
       "      <td>Spain's Barcelona</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flowing water causes sediment to move. Flowing...</td>\n",
       "      <td>How long does it take for water to dissolve ro...</td>\n",
       "      <td>Few  days</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How would the universe look without gravity? I...</td>\n",
       "      <td>How would the universe look without gravity?</td>\n",
       "      <td>No planets</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Let’s begin with a brief overview of spectacul...</td>\n",
       "      <td>What were economic conditions like before 1870?</td>\n",
       "      <td>Slow technological progress, natural disasters...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Let’s begin with a brief overview of spectacul...</td>\n",
       "      <td>What were economic conditions like before 1870?</td>\n",
       "      <td>Economic conditions before 1870 were sluggish ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Let’s begin with a brief overview of spectacul...</td>\n",
       "      <td>What were economic conditions like before 1870?</td>\n",
       "      <td>economic conditions were slow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Let’s begin with a brief overview of spectacul...</td>\n",
       "      <td>What were economic conditions like before 1870?</td>\n",
       "      <td>Before 1870, economic conditions were relative...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>Consider a program that outputs all even numbe...</td>\n",
       "      <td>What is the purpose of a do loop in JavaScript?</td>\n",
       "      <td>The purpose of a \"do . . . while \" loop in Jav...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5560 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             chunk_text  \\\n",
       "0     A flood occurs when a river overflows its bank...   \n",
       "1     Force is a vector. What then is a vector? Thin...   \n",
       "2     Madrid, Spain (CNN) -- Relatives of a woman ki...   \n",
       "3     Flowing water causes sediment to move. Flowing...   \n",
       "4     How would the universe look without gravity? I...   \n",
       "...                                                 ...   \n",
       "1053  Let’s begin with a brief overview of spectacul...   \n",
       "1054  Let’s begin with a brief overview of spectacul...   \n",
       "1055  Let’s begin with a brief overview of spectacul...   \n",
       "1056  Let’s begin with a brief overview of spectacul...   \n",
       "1057  Consider a program that outputs all even numbe...   \n",
       "\n",
       "                                               question  \\\n",
       "0     What forms the raised strip near the edge of a...   \n",
       "1     What two pieces of information does a vector p...   \n",
       "2     Where was the Spanish MD82 bound for when the ...   \n",
       "3     How long does it take for water to dissolve ro...   \n",
       "4          How would the universe look without gravity?   \n",
       "...                                                 ...   \n",
       "1053    What were economic conditions like before 1870?   \n",
       "1054    What were economic conditions like before 1870?   \n",
       "1055    What were economic conditions like before 1870?   \n",
       "1056    What were economic conditions like before 1870?   \n",
       "1057    What is the purpose of a do loop in JavaScript?   \n",
       "\n",
       "                                               response  label  \n",
       "0                                          Sandy desert      1  \n",
       "1                                   Motion and distance      2  \n",
       "2                                     Spain's Barcelona      1  \n",
       "3                                             Few  days      1  \n",
       "4                                            No planets      2  \n",
       "...                                                 ...    ...  \n",
       "1053  Slow technological progress, natural disasters...      4  \n",
       "1054  Economic conditions before 1870 were sluggish ...      2  \n",
       "1055                      economic conditions were slow      2  \n",
       "1056  Before 1870, economic conditions were relative...      2  \n",
       "1057  The purpose of a \"do . . . while \" loop in Jav...      4  \n",
       "\n",
       "[5560 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_df1 = (\n",
    "    pd.read_csv(multirc_path)\n",
    "    [[\"chunk_text\", \"question\", \"response\", \"gpt5_score\"]]\n",
    "    .rename(columns={\"gpt5_score\": \"label\"})\n",
    ")\n",
    "train_dev_df2 = (\n",
    "    pd.read_csv(authentic_path)\n",
    "    [[\"chunk_text\", \"question\", \"response\", \"o3_mini_score\"]]\n",
    "    .rename(columns={\"o3_mini_score\": \"label\"})\n",
    ")\n",
    "test_df = (\n",
    "    pd.read_csv(test_data_path)\n",
    "    [[\"chunk_text\", \"question\", \"response\", \"human_score\"]]\n",
    "    .rename(columns={\"human_score\": \"label\"})\n",
    ")\n",
    "\n",
    "train_dev_df = pd.concat([train_dev_df1, train_dev_df2])\n",
    "train_dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dba5c5c-b37a-4563-95dc-e137374537d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['chunk_text', 'question', 'response', 'label'],\n",
       "        num_rows: 5004\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['chunk_text', 'question', 'response', 'label'],\n",
       "        num_rows: 370\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['chunk_text', 'question', 'response', 'label'],\n",
       "        num_rows: 556\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_ds = datasets.Dataset.from_pandas(train_dev_df, preserve_index=False)\n",
    "dd = train_dev_ds.train_test_split(test_size=0.10, seed=42)\n",
    "dd[\"dev\"] = dd[\"test\"]\n",
    "\n",
    "test_ds = datasets.Dataset.from_pandas(test_df, preserve_index=False)\n",
    "dd[\"test\"] = test_ds\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4fdba60-9761-494b-a480-c92f32eaa8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f0f36f5c2d455d95b7b82c4b47bac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfc4c80d3e34a25b74ff27dd5b763a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/370 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789851a482d9407791618a0f6e0c1c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/556 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd.save_to_disk(datadict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6f3f0-dced-45b7-89e3-052756587d30",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d3da4fc-af71-4e90-9339-da8c3c61e997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df05c78e2e2c4d26a9d9e4332868bddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/5004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82966d83f4eb41bc9c9998c402bd62b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/370 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a4728b8ac1438182d67ebdd3df4836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/556 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5004\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 370\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 556\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_function(example):\n",
    "    input_str = f'{example[\"chunk_text\"]}\\n\\n\\n{example[\"question\"]}\\n\\n\\n{example[\"response\"]}'\n",
    "    new_example = tokenizer(input_str)\n",
    "    # new_example[\"label\"] = example[\"label\"] - 1 # Rescale labels to [0, 3] range\n",
    "    return tokenizer(input_str)\n",
    "\n",
    "dd = datasets.DatasetDict.load_from_disk(datadict_path)\n",
    "dd = dd.map(\n",
    "    preprocess_function,\n",
    "    batched=False,\n",
    "    remove_columns=[\n",
    "        \"chunk_text\", \"question\", \"response\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Convert label column to float type\n",
    "new_features = dd[\"train\"].features.copy()\n",
    "new_features[\"label\"] = datasets.Value(\"float32\")\n",
    "dd = dd.cast(new_features)\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee9ad9-7e8d-4b6b-94b6-5cc0f829a71f",
   "metadata": {},
   "source": [
    "## Set Up Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9af1e3a2-88e1-4dd3-8688-a13490da6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    \"Distracted\": 0,\n",
    "    \"Borderline\": 1,\n",
    "    \"Proficient\": 2,\n",
    "    \"Expert\": 3,\n",
    "}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=1,\n",
    "        # label2id=label2id,\n",
    "        # id2label=id2label,\n",
    "    )   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0244fcb-856a-4ab4-bd92-9214ad2b5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    eval_pred : tuple\n",
    "        A tuple of (logits, labels) provided by the Hugging Face Trainer.\n",
    "        - logits: numpy array of shape (n_samples, 2) for binary classification\n",
    "        - labels: numpy array of shape (n_samples,)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing:\n",
    "        - accuracy: Accuracy score\n",
    "        - precision: Precision score\n",
    "        - recall: Recall score\n",
    "        - f1: F1 score\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = metrics.accuracy_score(labels, preds)\n",
    "    \n",
    "    # Calculate precision, recall, f1\n",
    "    precision, recall, f1, _ = metrics.precision_recall_fscore_support(\n",
    "        labels, \n",
    "        preds, \n",
    "        average='macro',\n",
    "        zero_division=0,\n",
    "    )\n",
    "    \n",
    "    # Return metrics dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b55723b-3cad-4e5e-9ce2-3fb88b5cbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09cee7-6e5c-44b3-b0e2-d048fd25952b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1056' max='10008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1056/10008 01:53 < 16:07, 9.25 it/s, Epoch 0.84/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    bf16 = True, # bfloat16 training \n",
    "    optim = \"adamw_torch_fused\",\n",
    "    num_train_epochs = num_epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    learning_rate = learning_rate,\n",
    "    logging_dir = \"../../logs\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    seed = seed,\n",
    "    log_level = 'error',  \n",
    "    disable_tqdm = False, \n",
    "    report_to = \"none\", # Disable WandB reporting\n",
    ") \n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init = model_init,\n",
    "    args = training_args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset = dd[\"train\"],\n",
    "    eval_dataset = dd[\"dev\"],\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa884148-800b-4750-9c38-61cde20ca0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../../results/modernbert_authentic_multirc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11253d3a-95b4-4d00-8066-f56f16cd56cf",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef7572-2d99-4d3c-97ea-ff9ab3670c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    " \n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\", \n",
    "    model=\"../../results/modernbert_authentic_multirc\",\n",
    "    tokenizer=model_name_or_path,\n",
    "    device=0,\n",
    ")\n",
    " \n",
    "sample = \"Smoking is bad for your health.\"\n",
    " \n",
    "classifier(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
