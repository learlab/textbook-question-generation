{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e4ee57-b0be-409a-909b-9a6c78244cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.0 transformers-4.49.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pyarrow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956f09b7-dc26-4bc7-9e63-43298c96464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path_modernbert = \"answerdotai/ModernBERT-base\"\n",
    "model_name_or_path_mpnet = \"microsoft/mpnet-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0971a061-c08d-47d2-86f7-19a7cf4afc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "[2025-03-06 23:25:48,564] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (8)\n",
      "[2025-03-06 23:25:48,564] torch._dynamo.convert_frame: [WARNING]    function: 'compiled_mlp' (/opt/conda/lib/python3.11/site-packages/transformers/models/modernbert/modeling_modernbert.py:552)\n",
      "[2025-03-06 23:25:48,564] torch._dynamo.convert_frame: [WARNING]    last reason: ___guarded_code.valid\n",
      "[2025-03-06 23:25:48,564] torch._dynamo.convert_frame: [WARNING] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "[2025-03-06 23:25:48,564] torch._dynamo.convert_frame: [WARNING] To diagnose recompilation issues, see https://pytorch.org/docs/master/compile/troubleshooting.html.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'correct', 'score': 0.9971206188201904}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_modernbert = pipeline(\n",
    "    task=\"text-classification\", \n",
    "    model=\"../results/modernbert_multirc\",\n",
    "    tokenizer=model_name_or_path_modernbert,\n",
    "    device=0,\n",
    ")\n",
    " \n",
    "sample = \"Smoking is bad for your health.\"\n",
    " \n",
    "pipe_modernbert(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995a5a06-6f23-44a6-8313-b5a467142ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'incorrect_answer', 'score': 0.696195662021637}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_mpnet = pipeline(\n",
    "    task=\"text-classification\", \n",
    "    model=\"../bin/mpnet_classifier\",\n",
    "    tokenizer=model_name_or_path_mpnet,\n",
    "    device=0,\n",
    ")\n",
    " \n",
    "sample = \"Smoking is bad for your health.\"\n",
    " \n",
    "pipe_mpnet(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404852c-1e24-484b-b449-63b28a9753e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../bin/multirc_dataset.hf\"\n",
    "\n",
    "ds = datasets.DatasetDict.load_from_disk(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db2be4-8090-45e9-b9a8-f38b8766a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(pipe, dataset, label_key=\"label\"):\n",
    "    preds, labels = [], []\n",
    "    \n",
    "    for example in dataset[\"test\"]:\n",
    "        text = example[\"text\"]\n",
    "        label = example[label_key]\n",
    "        \n",
    "        result = pipe(text)\n",
    "        pred_label = int(result[0][\"label\"][-1])  # Assuming label format like \"LABEL_0\" or \"LABEL_1\"\n",
    "        \n",
    "        preds.append(pred_label)\n",
    "        labels.append(label)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(labels, preds)\n",
    "    f1 = metrics.f1_score(labels, preds, average=\"weighted\")\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ffcdf-67f8-499c-9f23-da20c355b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "modernbert_metrics = evaluate_model(modernbert_pipe, ds)\n",
    "mpnet_metrics = evaluate_model(mpnet_pipe, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67feb0e0-7db7-48aa-9707-c3681c8c018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ModernBERT Metrics:\")\n",
    "print(f\"Accuracy: {modernbert_metrics[0]:.4f}, F1 Score: {modernbert_metrics[1]:.4f}\")\n",
    "\n",
    "print(\"\\nMPNet Metrics:\")\n",
    "print(f\"Accuracy: {mpnet_metrics[0]:.4f}, F1 Score: {mpnet_metrics[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df42b0b-422f-48e8-bb8f-f8dbd4bd2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Accuracy\", \"F1 Score\"]\n",
    "modernbert_values = list(modernbert_metrics)\n",
    "mpnet_values = list(mpnet_metrics)\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, modernbert_values, width, label='ModernBERT')\n",
    "rects2 = ax.bar(x + width/2, mpnet_values, width, label='MPNet')\n",
    "\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Model Performance Comparison\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
