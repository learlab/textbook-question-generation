{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3946cfc-f8b0-4f18-bd93-a431cb472d8a",
   "metadata": {},
   "source": [
    "# Evaluate Finetuned Model Performance\n",
    "\n",
    "Our current ensemble correlates with the test data at Spearman's r of 0.51. The raw o3-mini scores were correlated at 0.70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d545d92-1c06-4595-a9e6-8634dd5d3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import pipeline\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46d3a50-69f1-4c52-a6cc-13ba1e5faca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict_path = \"../../data/authentic-03-scores-multirc-gpt5-scores.hf\" # The prepared training and validation data\n",
    "model_name_or_path = \"answerdotai/ModernBERT-base\"\n",
    "finetuned_model_path = \"../../results/modernbert_authentic_multirc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2772333d-9f93-4c94-a807-d8e00022f26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_str'],\n",
       "        num_rows: 5004\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_str'],\n",
       "        num_rows: 370\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['label', 'input_str'],\n",
       "        num_rows: 556\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_inputs(example):\n",
    "    input_str = f'{example[\"chunk_text\"]}\\n\\n\\n{example[\"question\"]}\\n\\n\\n{example[\"response\"]}'\n",
    "    example[\"input_str\"] = input_str\n",
    "    return example\n",
    "\n",
    "dd = datasets.DatasetDict.load_from_disk(datadict_path)\n",
    "dd = dd.map(\n",
    "    format_inputs,\n",
    "    batched=False,\n",
    "    remove_columns=[\n",
    "        \"chunk_text\", \"question\", \"response\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Convert label column to float type\n",
    "new_features = dd[\"train\"].features.copy()\n",
    "new_features[\"label\"] = datasets.Value(\"float32\")\n",
    "dd = dd.cast(new_features)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52bb7c25-3f7b-4728-b84d-75eb8d4d65be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\", \n",
    "    model=finetuned_model_path,\n",
    "    tokenizer=model_name_or_path,\n",
    "    device=0,\n",
    ")\n",
    " \n",
    "results = classifier(dd[\"test\"][\"input_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7bcbad-edf4-4b8a-8e73-f12e2c81e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dd[\"test\"][\"label\"]\n",
    "preds = [round(result[\"score\"]) for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c6911dc-804b-4eca-ad47-9cd36c4eb2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.8054\n",
      "RMSE: 0.8974\n",
      "MAE: 0.6432\n",
      "R2: 0.2939\n",
      "QWK: 0.5690\n",
      "LWK: 0.4031\n",
      "KAPPA: 0.2322\n",
      "SPEARMAN: 0.5815\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(preds, labels):\n",
    "    \"\"\"\n",
    "    Calculate multiple evaluation metrics using sklearn.\n",
    "    \n",
    "    Args:\n",
    "        preds: List of float predictions\n",
    "        labels: List of float true labels\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing calculated metrics\n",
    "    \"\"\"\n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    metric_dict = {}\n",
    "    \n",
    "    # Regression metrics\n",
    "    metric_dict['mse'] = metrics.mean_squared_error(labels, preds)\n",
    "    metric_dict['rmse'] = metrics.mean_squared_error(labels, preds, squared=False)\n",
    "    metric_dict['mae'] = metrics.mean_absolute_error(labels, preds)\n",
    "    metric_dict['r2'] = metrics.r2_score(labels, preds)\n",
    "    \n",
    "    # Classification metrics (round to integers for ordinal ratings)\n",
    "    preds_int = np.round(preds).astype(int)\n",
    "    labels_int = np.round(labels).astype(int)\n",
    "    \n",
    "    # Quadratic Weighted Kappa\n",
    "    metric_dict['qwk'] = metrics.cohen_kappa_score(labels_int, preds_int, weights='quadratic')\n",
    "    \n",
    "    # Linear Weighted Kappa (bonus)\n",
    "    metric_dict['lwk'] = metrics.cohen_kappa_score(labels_int, preds_int, weights='linear')\n",
    "    \n",
    "    # Regular Cohen's Kappa\n",
    "    metric_dict['kappa'] = metrics.cohen_kappa_score(labels_int, preds_int)\n",
    "\n",
    "    # Spearman's r\n",
    "    metric_dict[\"spearman\"] = stats.spearmanr(labels_int, preds_int).statistic\n",
    "\n",
    "    return metric_dict\n",
    "\n",
    "metrics = calculate_metrics(preds, labels)\n",
    "\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric.upper()}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
