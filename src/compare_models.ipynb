{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386ad11e-a333-4d75-b31e-e5ba0445290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.4)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Using cached huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.29.3 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.49.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6130a5ec-a0d0-44a8-ad52-52e9eceb3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnet_model = \"tiedaar/short-answer-classification\"\n",
    "bleurt_model = \"vaiibhavgupta/finetuned-bleurt-large\"\n",
    "modernbert_model = \"answerdotai/ModernBERT-base\"\n",
    "bleurt_threshold = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c5ad0e8-6682-408c-b928-cd7c6ae1f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bleurt():\n",
    "    model_name = \"vaiibhavgupta/finetuned-bleurt-large\"\n",
    "    threshold = 0.7\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=self.model_name,\n",
    "            device=\"cuda\",\n",
    "        )\n",
    "\n",
    "    def __call__(self, candidate: str, reference: str) -> int:\n",
    "        sequence = f\"{candidate}[SEP]{reference}\"\n",
    "\n",
    "        result = self.classifier(sequence)\n",
    "        score = result[0][\"score\"]\n",
    "\n",
    "        return 1 if score > self.threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22763d7d-5d2c-4f73-b3c4-dbac5fb2314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mpnet():\n",
    "    model_name = \"tiedaar/short-answer-classification\"\n",
    "    revision = \"77b846ec4606bfcfdf913888d7f0ab51f977a579\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=self.model_name,\n",
    "            revision=self.revision,\n",
    "            device=\"cuda\",\n",
    "            )\n",
    "\n",
    "    def __call__(self, candidate: str, reference: str) -> int:\n",
    "        sequence = f\"{candidate}</s>{reference}\"\n",
    "\n",
    "        result = self.classifier(sequence)\n",
    "        label = result[0][\"label\"]\n",
    "\n",
    "        return 1 if label == \"correct_answer\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bd994b5-2306-44ee-bfd0-44cb4412fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "class ModernBERT:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\") ## change model_path??\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\"../results/modernbert_multirc\")\n",
    "        self.model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    def predict(self, text):\n",
    "        # Tokenize input\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # Process outputs to get predictions\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "        return  1 if predicted_class == 1 else 0\n",
    "\n",
    "# add tokenizer, use local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f3c58ac-3bd7-42e5-bb4f-6d2d39f25407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpnet = Mpnet()\n",
    "# bleurt = Bleurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04f30d8-c3e9-4253-b7b4-35cd116136db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnet(\"This a strong answer to the question\", \"This is a reference answer to the question\")  # Scored incorrect (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9964cb6c-89d2-41c3-b0f4-b415934ff2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleurt(\"This a strong answer to the question\", \"This is a reference answer to the question\")  # Scored correct (1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
