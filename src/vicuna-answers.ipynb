{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29910439-60bb-4877-813d-9d4291ee797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from transformers import pipeline, LlamaForCausalLM\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "import datasets\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.base import Chain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.output_parsers.regex_dict import RegexDictParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63fdc51b-22c7-426f-add2-aacfbe0035c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/jovyan/conda_envs/peft/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/jovyan/conda_envs/peft/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /home/jovyan/conda_envs/peft/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef02da58c9d452fb85f18b50f7eb385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_location = '/home/jovyan/project-archive/vicuna-7b'\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "        model_location,\n",
    "        load_in_8bit=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map={'': Accelerator().local_process_index},\n",
    "        max_length=4096\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4971fe84-cbb2-4d01-8277-b0532f47a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(model=model,\n",
    "                tokenizer=model_location,\n",
    "                use_fast=False,\n",
    "                task='text-generation',\n",
    "                model_kwargs={'load_in_8bit': True},\n",
    "                max_length=4096,\n",
    "                temperature=0.9,\n",
    "                top_p=0.95,\n",
    "                repetition_penalty=1.1,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe180aa0-0ba6-4f04-90d6-588151410553",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e003972a-fbed-4d04-b9a5-4fbeeee9ba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'module', 'chapter', 'section', 'subsection', 'heading',\n",
       "       'raw_text', 'clean_text', 'slug', 'question', 'correct_answer',\n",
       "       'incorrect_answer', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/aqag-chatgpt.csv', index_col=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7deee3a-ea07-44eb-ac8d-bcef5f942573",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_response_template = (\n",
    "    'The following is a passage from a macroeconomics textbook. Use the passage to generate a correct response to the question. '\n",
    "    'The response should fully and directly address the question with no conceptual or factual errors. '\n",
    "    'The response should be written in the voice of a student who has carefully read and understood the passage. '\n",
    "    'The response should be written in 1-2 complete sentences.\\n\\n'\n",
    "    'Passage:\\n{source}\\n\\n'\n",
    "    'Question:\\n{question}\\n\\n'\n",
    "    'Response:\\n'\n",
    ")\n",
    "\n",
    "correct_response_prompt = PromptTemplate(\n",
    "    input_variables=['source', 'question'],\n",
    "    template=correct_response_template,\n",
    ")\n",
    "\n",
    "correct_response_chain = LLMChain(llm=llm, prompt=correct_response_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ec9610c-199e-4bf7-8052-99f606fab3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct_answer_vicuna': 'Scarcity refers to the limited availability of resources, including labor, tools, land, and raw materials, which are necessary to produce goods and services but exist in limited supply.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correct_response(example):\n",
    "    question = correct_response_chain.run(source = example['raw_text'], question = example['question'])\n",
    "    return {'correct_answer_vicuna': question}\n",
    "\n",
    "correct_response(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a18811d6-4881-4e04-a20a-b5274e0fe3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1569 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets.Dataset.from_pandas(df)\n",
    "ds1 = ds.map(correct_response)\n",
    "df1 = ds1.to_pandas().drop(columns = '__index_level_0__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5e57d55-340a-44a6-8e01-3f51df3a1885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('../data/aqag-chatgpt-vicuna.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f4f32-dfa2-44cb-bfce-07fe53e4a589",
   "metadata": {},
   "source": [
    "# Sample the questions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6dbec5e-a487-499b-a938-8d6b76e4b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/aqag-chatgpt-vicuna.csv', index_col=0)\n",
    "df['id'] = df.apply(lambda row: str(row['index']) + '-' + row['type'], axis=1)\n",
    "\n",
    "df = df[['id','slug', 'clean_text', 'type', 'question', 'correct_answer', 'correct_answer_vicuna', 'incorrect_answer']].dropna()\n",
    "\n",
    "df.columns =['id', 'slug', 'clean_text', 'type', 'question_gpt', 'correct_answer_gpt', 'correct_answer_vicuna', 'incorrect_answer_gpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8d8c2f2-2c90-429b-98b2-817b541dd6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "df_types = []\n",
    "for type in df['type'].drop_duplicates():\n",
    "    temp_df = df[df['type'] == type].sample(20)\n",
    "    df_types.append(temp_df)\n",
    "sampled_df = pd.concat(df_types)\n",
    "print(len(sampled_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d4b1097-d8c9-4fed-8955-f36cb2f1ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.to_csv('../data/AQAG_chatgpt_vicuna_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae15f20-06c1-4a70-a26e-1fe375d2df9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:peft]",
   "language": "python",
   "name": "conda-env-peft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
