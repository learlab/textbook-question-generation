{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2826c2df-5c46-4ae7-aeb8-23c6eda53de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a36a8c-2055-46c0-815d-004fc958b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = '../data/multirc-v2/'\n",
    "TRAIN_FILE = 'train_456-fixedIds.json'\n",
    "DEV_FILE = 'dev_83-fixedIds.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f71060a-fea7-4890-927c-efc70f135b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FOLDER+TRAIN_FILE) as f:\n",
    "    train_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "faf896c5-97fd-4372-ac2b-7d4377f71ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(input_json):\n",
    "    output_dict = {\"source_id\":[], \"source_text\":[], \"question_text\":[], \"answer_text\":[], \"is_correct\":[]}\n",
    "\n",
    "    for item in input_json['data']:\n",
    "        source_id = item['id']\n",
    "        paragraph = item['paragraph']\n",
    "        source_text = paragraph['text']\n",
    "        for question in paragraph['questions']:\n",
    "            question_text = question['question']\n",
    "            for answer in question['answers']:\n",
    "                answer_text = answer['text']\n",
    "                is_correct = answer['isAnswer']\n",
    "                output_dict[\"is_correct\"].append(is_correct)\n",
    "                output_dict[\"answer_text\"].append(answer_text)\n",
    "                output_dict[\"question_text\"].append(question_text)\n",
    "                output_dict[\"source_id\"].append(question_id)\n",
    "                output_dict[\"source_text\"].append(source_text)\n",
    "    \n",
    "        df = pd.DataFrame.from_dict(output_dict)\n",
    "        \n",
    "        def clean_text(s):\n",
    "            new_string = re.sub('<b>.+?</b>', '', s)\n",
    "            new_string = re.sub('<br>', '\\n', new_string)\n",
    "            return new_string\n",
    "        df['source_text_clean'] = df['source_text'].apply(clean_text)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9c7914fa-b16d-4aeb-97e0-2ce55e1a27f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b7042e31-6fcd-4f62-bef2-14721763c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "model = OpenAI(temperature=0.3, openai_api_key = openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fec39c8d-9043-4ed7-bcbf-f7d8a92179b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"please use the passage to provide a short answer to this question.\\n Question:{question}\\nPassage:{passage}\",\n",
    "    input_variables=[\"question\", \"passage\"],\n",
    ")\n",
    "\n",
    "def get_answer(example):\n",
    "    _input = prompt.format_prompt(passage=example['source_text_clean'], question=example['question_text'])\n",
    "    output = model(_input.to_string())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f7655-bf6e-41f3-82c8-b30fa3325031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3941/5131 [57:34<17:08,  1.16it/s]  "
     ]
    }
   ],
   "source": [
    "questions_df = df[['question_text', 'source_text_clean']].drop_duplicates()\n",
    "questions_df['gpt_answers'] = questions_df.progress_apply(lambda row: get_answer(row), axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
