{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca8307-d10b-4f49-a50c-e00473c7d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score, confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320dc04-d3e9-4c30-96ef-053d6ca56c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(predicted_labels_raw, true_labels, return_metrics=False):\n",
    "\n",
    "    plt.hist(predicted_labels_raw)\n",
    "    plt.title('BLEURT Score Distribution')\n",
    "    plt.show()\n",
    "\n",
    "    max_f1_at_th = -1.0\n",
    "    max_f1 = 0.0\n",
    "    \n",
    "    for th in np.arange(0.5, 1.0, 0.05):\n",
    "        th = round(th, 2)\n",
    "        predicted_labels = [1 if bleurt_score >= th else 0 for bleurt_score in predicted_labels_raw]\n",
    "\n",
    "        temp_f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "        if temp_f1 >= max_f1:\n",
    "            max_f1 = temp_f1\n",
    "            max_f1_at_th = th\n",
    "\n",
    "    # printing metrics at the threshold for which we got max F1-Score\n",
    "    predicted_labels = [1 if bleurt_score >= max_f1_at_th else 0 for bleurt_score in predicted_labels_raw]        \n",
    "\n",
    "    if return_metrics:\n",
    "        return max_f1_at_th, f1_score(true_labels, predicted_labels), cohen_kappa_score(true_labels, predicted_labels)\n",
    "    else:\n",
    "        print(f'Optimal Thresohld: {max_f1_at_th} \\n')\n",
    "        print(f'Predicted Label Count: {Counter(predicted_labels)}\\n')\n",
    "        print('Classification Report:')\n",
    "        print(classification_report(true_labels, predicted_labels), '\\n')\n",
    "        print('F1 Score: ', f1_score(true_labels, predicted_labels), '\\n')\n",
    "        print('Cohen Kappa: ', cohen_kappa_score(true_labels, predicted_labels), '\\n')\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(true_labels, predicted_labels), display_labels = ['incorrect', 'correct'])\n",
    "        cm_display.plot()\n",
    "        plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ddbe72-6369-4c26-9ee8-f7511eed9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLEURTDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        candidate = item[\"candidate\"]\n",
    "        reference = item[\"reference\"]\n",
    "        score = item[\"score\"]\n",
    "        encoding = self.tokenizer(candidate, reference, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(score, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6788c-4195-42ef-858f-25fdbf24116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"/home/jovyan/active-projects/textbook-question-generation/bleurt-models/bleurtmodel/bleurt/bleurt/test_data/chatgpt-vicuna/{}_samples.jsonl\"\n",
    "# model_save_path = \"/home/jovyan/active-projects/textbook-question-generation/src/chatgpt-vicuna-bleurt/\"\n",
    "unique_identifier = \"20230912\"\n",
    "dataset_name = \"multirc\"\n",
    "data_path = \"/home/jovyan/active-projects/textbook-question-generation/bleurt-models/bleurtmodel/bleurt/bleurt/test_data/\"+dataset_name+\"-dataset/{}_samples.jsonl\"\n",
    "model_save_path = f\"/home/jovyan/active-projects/textbook-question-generation/src/{dataset_name}-bleurt/\"\n",
    "\n",
    "model_type = \"large\"\n",
    "num_training_epochs = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a30d428-4e5b-4ad9-a0b5-b96fb7011295",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_model_already_trained = False\n",
    "\n",
    "if is_model_already_trained:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_save_path+f'model_{model_type}_'+unique_identifier)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_save_path+f'tokenizer_{model_type}_'+unique_identifier)\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(f\"Elron/bleurt-{model_type}-128\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(f\"Elron/bleurt-{model_type}-128\")\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ec4ca-17b6-4ce9-9d3f-72c8bbfdd45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path.format('train'), 'r') as file:\n",
    "    train_samples = [json.loads(line) for line in file]\n",
    "\n",
    "with open(data_path.format('validation'), 'r') as file:\n",
    "    validation_samples = [json.loads(line) for line in file]\n",
    "\n",
    "train_dataset = BLEURTDataset(train_samples, tokenizer)\n",
    "validation_dataset = BLEURTDataset(validation_samples, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935dfc8-48f6-4b67-ae8c-7f466fb7c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.to(device)\n",
    "assert device.type == 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad5435f-8b1e-4e9d-9645-f9523ac49362",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_model_already_trained:\n",
    "\n",
    "    temp_vp = []\n",
    "    temp_vtl = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(validation_loader):\n",
    "            temp_vtl.extend(batch['labels'])\n",
    "            \n",
    "            outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "            logits = outputs.logits\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            temp_vp.extend(preds)\n",
    "    \n",
    "    _, best_f1_score, _ = generate_metrics([arr[0] for arr in temp_vp], [t.item() for t in temp_vtl], return_metrics=True)\n",
    "\n",
    "else:\n",
    "    best_f1_score = -1\n",
    "\n",
    "best_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe17cc23-670a-4e09-bc32-83a2756035b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs_validation_losses = []\n",
    "all_epochs_training_losses = []\n",
    "\n",
    "for epoch in range(num_training_epochs):\n",
    "    print(f\"Epoch {epoch + 1} of {num_training_epochs}:\")\n",
    "\n",
    "    predicted_labels_raw = []\n",
    "    true_labels = []\n",
    "    \n",
    "    epoch_training_loss = 0\n",
    "    epoch_validation_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "        outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device), labels=batch['labels'].to(device))\n",
    "        batch_training_loss = outputs.loss\n",
    "        epoch_training_loss += batch_training_loss.item()\n",
    "        batch_training_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(validation_loader):\n",
    "            true_labels.extend(batch['labels'])\n",
    "            outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device), labels=batch['labels'].to(device))\n",
    "            batch_validation_loss = outputs.loss\n",
    "            epoch_validation_loss += batch_validation_loss.item()\n",
    "            predicted_labels_raw.extend(outputs.logits.detach().cpu().numpy())\n",
    "            \n",
    "    all_epochs_training_losses.append(round(epoch_training_loss / len(train_loader), 2))\n",
    "    all_epochs_validation_losses.append(round(epoch_validation_loss / len(validation_loader), 2))\n",
    "\n",
    "    batch_optimal_threshold, batch_f1_score, batch_kappa = generate_metrics([arr[0] for arr in predicted_labels_raw], [t.item() for t in true_labels], return_metrics=True)\n",
    "\n",
    "    print(f\"\\tValidation loss: {all_epochs_validation_losses[-1]}\")\n",
    "    print(f\"\\tOptimal Threshold: {batch_optimal_threshold}\")\n",
    "    print(f\"\\tF1 Score: {batch_f1_score}\")\n",
    "    print(f\"\\tCohen Kappa: {batch_kappa}\")\n",
    "\n",
    "    if batch_f1_score > best_f1_score:\n",
    "        print(f\"\\n\\tSaving this epoch's model. Previous Best F1: {best_f1_score}, Current Best F1: {batch_f1_score}\")\n",
    "        best_f1_score = batch_f1_score\n",
    "        model.save_pretrained(model_save_path+f'model_{model_type}_'+unique_identifier)\n",
    "        tokenizer.save_pretrained(model_save_path+f'tokenizer_{model_type}_'+unique_identifier)\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ae16e-8b1e-44eb-b4f4-77dabb596936",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(num_training_epochs), all_epochs_training_losses, color='blue')\n",
    "plt.plot(range(num_training_epochs), all_epochs_validation_losses, color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05d134-4674-46e1-9339-6abd9ab35efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_best_model = AutoModelForSequenceClassification.from_pretrained(model_save_path+f'model_{model_type}_'+unique_identifier)\n",
    "ft_best_model.to(device)\n",
    "ft_best_model.eval()\n",
    "ft_best_tokenizer = AutoTokenizer.from_pretrained(model_save_path+f'tokenizer_{model_type}_'+unique_identifier)\n",
    "\n",
    "with open(data_path.format('test'), 'r') as file:\n",
    "    test_samples = [json.loads(line) for line in file]\n",
    "\n",
    "test_dataset = BLEURTDataset(test_samples, ft_best_tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a4880-60e7-4879-93e4-1813cca16e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(test_loader):\n",
    "        true_labels.extend(batch['labels'])\n",
    "        \n",
    "        outputs = ft_best_model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "        logits = outputs.logits\n",
    "        preds = logits.detach().cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "generate_metrics([arr[0] for arr in predictions], [tn.item() for tn in true_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f0da4-41f7-4fa9-bab8-57eda8caf64d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hanlin)",
   "language": "python",
   "name": "hanlin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
